{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, there is one pattern occurring in the data. Solving just a classification task be scored no higher than 70%. \n",
    "\n",
    "Please provide either pdf with the report or add some notes in the notebook. Demonstrate some examples of how your approach works.\n",
    "\n",
    "A short reminder of your task:\n",
    " - Correct classification of provided time series\n",
    " - Explanation of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input, RepeatVector, TimeDistributed, Masking\n",
    "from tensorflow.keras.layers import Reshape, GlobalMaxPool1D, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRow(n, classes):\n",
    "    base = np.sin(np.linspace((np.random.rand(3)),(np.random.rand(3) + np.array([10,15,7])),n))\n",
    "    if classes[0] > 0:\n",
    "        base[np.random.randint(0,n), 0] += 2\n",
    "    if classes[1] > 0:\n",
    "        base[np.random.randint(0,n), 1] -= 2\n",
    "    if classes[2] > 0:\n",
    "        x = np.random.randint(0,n-5)\n",
    "        base[x:x+4,2] = 0\n",
    "    if classes[3] > 0:\n",
    "        x = np.random.randint(0,n-10)\n",
    "        base[x:x+8,1] += 1.5\n",
    "    if classes[4] > 0:\n",
    "        x = np.random.randint(0,n-7)\n",
    "        base[x:x+6,0] += 1.5\n",
    "        base[x:x+6,2] -= 1.5\n",
    "    base += np.random.rand(*base.shape)*.2\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl, ll, yl = [], [], []\n",
    "for _ in range(n):\n",
    "    cl = (np.random.rand(5)<.25).astype(np.float32)\n",
    "    row = createRow(np.random.randint(40,60), cl)\n",
    "    ll.append([_,len(row)])\n",
    "    xl.append(row)\n",
    "    yl.append(cl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 10:34:58.235060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:34:58.315273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:34:58.315722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 10:35:00.628689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-05 10:35:00.631310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:00.631793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:00.632188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:02.100402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:02.100854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:02.101236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-05 10:35:02.101584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([50000, 59, 3]), TensorShape([50000, 5]), TensorShape([50000, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(\n",
    "    xl, padding=\"post\", dtype=\"float32\"\n",
    ")\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(yl, dtype=tf.float32)\n",
    "lengths = tf.convert_to_tensor(ll, dtype=tf.int32)\n",
    "X.shape, y.shape, lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = X[:35000], y[:35000], X[35000:], y[35000:]\n",
    "lengths_train, lengths_valid = lengths[:35000], lengths[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([35000, 59, 3]), TensorShape([35000, 5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "69/69 [==============================] - 6s 31ms/step - loss: 0.5995 - acc: 0.1498 - precision_2: 0.2743 - recall_2: 0.4866 - val_loss: 0.5323 - val_acc: 0.1746 - val_precision_2: 0.4193 - val_recall_2: 0.4055\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4929 - acc: 0.2331 - precision_2: 0.5960 - recall_2: 0.3848 - val_loss: 0.4604 - val_acc: 0.2591 - val_precision_2: 0.7080 - val_recall_2: 0.3906\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4514 - acc: 0.3659 - precision_2: 0.8123 - recall_2: 0.3479 - val_loss: 0.4534 - val_acc: 0.4556 - val_precision_2: 0.8794 - val_recall_2: 0.3228\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4272 - acc: 0.4273 - precision_2: 0.9822 - recall_2: 0.3468 - val_loss: 0.4183 - val_acc: 0.3699 - val_precision_2: 0.9872 - val_recall_2: 0.3492\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.4123 - acc: 0.3719 - precision_2: 0.9603 - recall_2: 0.3566 - val_loss: 0.4034 - val_acc: 0.3233 - val_precision_2: 0.9555 - val_recall_2: 0.3709\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3929 - acc: 0.3715 - precision_2: 0.8805 - recall_2: 0.4180 - val_loss: 0.3844 - val_acc: 0.3300 - val_precision_2: 0.9148 - val_recall_2: 0.4099\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.3788 - acc: 0.3282 - precision_2: 0.8972 - recall_2: 0.4348 - val_loss: 0.3691 - val_acc: 0.3407 - val_precision_2: 0.8765 - val_recall_2: 0.4514\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3665 - acc: 0.3162 - precision_2: 0.8744 - recall_2: 0.4758 - val_loss: 0.3575 - val_acc: 0.3339 - val_precision_2: 0.8564 - val_recall_2: 0.5116\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3579 - acc: 0.3168 - precision_2: 0.8421 - recall_2: 0.5187 - val_loss: 0.3495 - val_acc: 0.3442 - val_precision_2: 0.7994 - val_recall_2: 0.5694\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3520 - acc: 0.3157 - precision_2: 0.8280 - recall_2: 0.5302 - val_loss: 0.3464 - val_acc: 0.3122 - val_precision_2: 0.8941 - val_recall_2: 0.4837\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3405 - acc: 0.3346 - precision_2: 0.8139 - recall_2: 0.5622 - val_loss: 0.3331 - val_acc: 0.3363 - val_precision_2: 0.7980 - val_recall_2: 0.5771\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.3350 - acc: 0.3255 - precision_2: 0.8224 - recall_2: 0.5571 - val_loss: 0.3253 - val_acc: 0.3521 - val_precision_2: 0.8081 - val_recall_2: 0.5874\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.3207 - acc: 0.3451 - precision_2: 0.8281 - recall_2: 0.5822 - val_loss: 0.3175 - val_acc: 0.3524 - val_precision_2: 0.8659 - val_recall_2: 0.5559\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.3174 - acc: 0.3500 - precision_2: 0.8217 - recall_2: 0.5816 - val_loss: 0.3116 - val_acc: 0.3499 - val_precision_2: 0.8447 - val_recall_2: 0.5732\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.3042 - acc: 0.3683 - precision_2: 0.8078 - recall_2: 0.6188 - val_loss: 0.3080 - val_acc: 0.3603 - val_precision_2: 0.8913 - val_recall_2: 0.5479\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2993 - acc: 0.3810 - precision_2: 0.8288 - recall_2: 0.6167 - val_loss: 0.3127 - val_acc: 0.3398 - val_precision_2: 0.8911 - val_recall_2: 0.5495\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2889 - acc: 0.4096 - precision_2: 0.8459 - recall_2: 0.6362 - val_loss: 0.2690 - val_acc: 0.4332 - val_precision_2: 0.8921 - val_recall_2: 0.6673\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2681 - acc: 0.4379 - precision_2: 0.8634 - recall_2: 0.6788 - val_loss: 0.2613 - val_acc: 0.4319 - val_precision_2: 0.8969 - val_recall_2: 0.6618\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2527 - acc: 0.4518 - precision_2: 0.8704 - recall_2: 0.6980 - val_loss: 0.2463 - val_acc: 0.4531 - val_precision_2: 0.8703 - val_recall_2: 0.6994\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2587 - acc: 0.4423 - precision_2: 0.8741 - recall_2: 0.6752 - val_loss: 0.2410 - val_acc: 0.4537 - val_precision_2: 0.9378 - val_recall_2: 0.6783\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2384 - acc: 0.4611 - precision_2: 0.9306 - recall_2: 0.6881 - val_loss: 0.2319 - val_acc: 0.4755 - val_precision_2: 0.9452 - val_recall_2: 0.6924\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2314 - acc: 0.4663 - precision_2: 0.9617 - recall_2: 0.6851 - val_loss: 0.2281 - val_acc: 0.4711 - val_precision_2: 0.9520 - val_recall_2: 0.6887\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2267 - acc: 0.4674 - precision_2: 0.9681 - recall_2: 0.6859 - val_loss: 0.2249 - val_acc: 0.4883 - val_precision_2: 0.9469 - val_recall_2: 0.6938\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2328 - acc: 0.4579 - precision_2: 0.9650 - recall_2: 0.6705 - val_loss: 0.2209 - val_acc: 0.4628 - val_precision_2: 0.9907 - val_recall_2: 0.6768\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2158 - acc: 0.4705 - precision_2: 0.9851 - recall_2: 0.6893 - val_loss: 0.2152 - val_acc: 0.4920 - val_precision_2: 0.9676 - val_recall_2: 0.6940\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2134 - acc: 0.4716 - precision_2: 0.9841 - recall_2: 0.6882 - val_loss: 0.2174 - val_acc: 0.5029 - val_precision_2: 0.9466 - val_recall_2: 0.6945\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2087 - acc: 0.4729 - precision_2: 0.9886 - recall_2: 0.6903 - val_loss: 0.2051 - val_acc: 0.4796 - val_precision_2: 0.9892 - val_recall_2: 0.6924\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2050 - acc: 0.4727 - precision_2: 0.9912 - recall_2: 0.6922 - val_loss: 0.2040 - val_acc: 0.4672 - val_precision_2: 0.9946 - val_recall_2: 0.6870\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2055 - acc: 0.4714 - precision_2: 0.9855 - recall_2: 0.6899 - val_loss: 0.2887 - val_acc: 0.3617 - val_precision_2: 0.9957 - val_recall_2: 0.5655\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2063 - acc: 0.4667 - precision_2: 0.9867 - recall_2: 0.6865 - val_loss: 0.1987 - val_acc: 0.4783 - val_precision_2: 0.9910 - val_recall_2: 0.6927\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1985 - acc: 0.4706 - precision_2: 0.9905 - recall_2: 0.6941 - val_loss: 0.1950 - val_acc: 0.4760 - val_precision_2: 0.9914 - val_recall_2: 0.6974\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1954 - acc: 0.4727 - precision_2: 0.9919 - recall_2: 0.6969 - val_loss: 0.1925 - val_acc: 0.4815 - val_precision_2: 0.9930 - val_recall_2: 0.6980\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1930 - acc: 0.4757 - precision_2: 0.9905 - recall_2: 0.6994 - val_loss: 0.1901 - val_acc: 0.4815 - val_precision_2: 0.9896 - val_recall_2: 0.7039\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1919 - acc: 0.4788 - precision_2: 0.9862 - recall_2: 0.7055 - val_loss: 0.1899 - val_acc: 0.5018 - val_precision_2: 0.9754 - val_recall_2: 0.7139\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1857 - acc: 0.4883 - precision_2: 0.9896 - recall_2: 0.7144 - val_loss: 0.1855 - val_acc: 0.4925 - val_precision_2: 0.9964 - val_recall_2: 0.7084\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1808 - acc: 0.4911 - precision_2: 0.9903 - recall_2: 0.7224 - val_loss: 0.1787 - val_acc: 0.4979 - val_precision_2: 0.9924 - val_recall_2: 0.7235\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1769 - acc: 0.4960 - precision_2: 0.9894 - recall_2: 0.7307 - val_loss: 0.1733 - val_acc: 0.4928 - val_precision_2: 0.9946 - val_recall_2: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1712 - acc: 0.4997 - precision_2: 0.9895 - recall_2: 0.7445 - val_loss: 0.1809 - val_acc: 0.5075 - val_precision_2: 0.9806 - val_recall_2: 0.7258\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1670 - acc: 0.4983 - precision_2: 0.9918 - recall_2: 0.7514 - val_loss: 0.1646 - val_acc: 0.4961 - val_precision_2: 0.9900 - val_recall_2: 0.7557\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1603 - acc: 0.4969 - precision_2: 0.9910 - recall_2: 0.7649 - val_loss: 0.1563 - val_acc: 0.5107 - val_precision_2: 0.9932 - val_recall_2: 0.7685\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1556 - acc: 0.4947 - precision_2: 0.9921 - recall_2: 0.7711 - val_loss: 0.1526 - val_acc: 0.4867 - val_precision_2: 0.9972 - val_recall_2: 0.7707\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1856 - acc: 0.4783 - precision_2: 0.9664 - recall_2: 0.7386 - val_loss: 0.2433 - val_acc: 0.5311 - val_precision_2: 0.9302 - val_recall_2: 0.6935\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1697 - acc: 0.4765 - precision_2: 0.9923 - recall_2: 0.7367 - val_loss: 0.1615 - val_acc: 0.4988 - val_precision_2: 0.9973 - val_recall_2: 0.7418\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1625 - acc: 0.4941 - precision_2: 0.9958 - recall_2: 0.7403 - val_loss: 0.1591 - val_acc: 0.4979 - val_precision_2: 0.9991 - val_recall_2: 0.7422\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1563 - acc: 0.4953 - precision_2: 0.9938 - recall_2: 0.7565 - val_loss: 0.1507 - val_acc: 0.5014 - val_precision_2: 0.9946 - val_recall_2: 0.7729\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1478 - acc: 0.4947 - precision_2: 0.9967 - recall_2: 0.7755 - val_loss: 0.1476 - val_acc: 0.4838 - val_precision_2: 0.9996 - val_recall_2: 0.7698\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1460 - acc: 0.4912 - precision_2: 0.9956 - recall_2: 0.7762 - val_loss: 0.1440 - val_acc: 0.5036 - val_precision_2: 0.9975 - val_recall_2: 0.7778\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1432 - acc: 0.4899 - precision_2: 0.9979 - recall_2: 0.7786 - val_loss: 0.1428 - val_acc: 0.4935 - val_precision_2: 0.9942 - val_recall_2: 0.7798\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1435 - acc: 0.4944 - precision_2: 0.9954 - recall_2: 0.7769 - val_loss: 0.1471 - val_acc: 0.4872 - val_precision_2: 1.0000 - val_recall_2: 0.7668\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1448 - acc: 0.4954 - precision_2: 0.9899 - recall_2: 0.7785 - val_loss: 0.2864 - val_acc: 0.3967 - val_precision_2: 0.9909 - val_recall_2: 0.6465\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1839 - acc: 0.4658 - precision_2: 0.9745 - recall_2: 0.7449 - val_loss: 0.1426 - val_acc: 0.4901 - val_precision_2: 0.9977 - val_recall_2: 0.7765\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1412 - acc: 0.4852 - precision_2: 0.9965 - recall_2: 0.7801 - val_loss: 0.1398 - val_acc: 0.4910 - val_precision_2: 0.9980 - val_recall_2: 0.7798\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1388 - acc: 0.4864 - precision_2: 0.9971 - recall_2: 0.7834 - val_loss: 0.1382 - val_acc: 0.4861 - val_precision_2: 0.9942 - val_recall_2: 0.7853\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1397 - acc: 0.4891 - precision_2: 0.9944 - recall_2: 0.7837 - val_loss: 0.1373 - val_acc: 0.5098 - val_precision_2: 0.9917 - val_recall_2: 0.7894\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1365 - acc: 0.4928 - precision_2: 0.9968 - recall_2: 0.7876 - val_loss: 0.1359 - val_acc: 0.4819 - val_precision_2: 0.9966 - val_recall_2: 0.7880\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1344 - acc: 0.4954 - precision_2: 0.9980 - recall_2: 0.7900 - val_loss: 0.1334 - val_acc: 0.4997 - val_precision_2: 0.9986 - val_recall_2: 0.7886\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1329 - acc: 0.4959 - precision_2: 0.9982 - recall_2: 0.7908 - val_loss: 0.1320 - val_acc: 0.4980 - val_precision_2: 0.9980 - val_recall_2: 0.7901\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1327 - acc: 0.4976 - precision_2: 0.9972 - recall_2: 0.7902 - val_loss: 0.1340 - val_acc: 0.4835 - val_precision_2: 0.9989 - val_recall_2: 0.7850\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1311 - acc: 0.4981 - precision_2: 0.9979 - recall_2: 0.7914 - val_loss: 0.1300 - val_acc: 0.5029 - val_precision_2: 0.9995 - val_recall_2: 0.7895\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1290 - acc: 0.4951 - precision_2: 0.9981 - recall_2: 0.7927 - val_loss: 0.1287 - val_acc: 0.5149 - val_precision_2: 0.9972 - val_recall_2: 0.7921\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1279 - acc: 0.4973 - precision_2: 0.9980 - recall_2: 0.7935 - val_loss: 0.1321 - val_acc: 0.5022 - val_precision_2: 0.9805 - val_recall_2: 0.7926\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1265 - acc: 0.4955 - precision_2: 0.9983 - recall_2: 0.7937 - val_loss: 0.1252 - val_acc: 0.4919 - val_precision_2: 0.9982 - val_recall_2: 0.7950\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1243 - acc: 0.4906 - precision_2: 0.9980 - recall_2: 0.7981 - val_loss: 0.1235 - val_acc: 0.5051 - val_precision_2: 0.9986 - val_recall_2: 0.7960\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1231 - acc: 0.4955 - precision_2: 0.9962 - recall_2: 0.8070 - val_loss: 0.1219 - val_acc: 0.5102 - val_precision_2: 0.9981 - val_recall_2: 0.8037\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1215 - acc: 0.4966 - precision_2: 0.9951 - recall_2: 0.8205 - val_loss: 0.1221 - val_acc: 0.5217 - val_precision_2: 0.9937 - val_recall_2: 0.8093\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1195 - acc: 0.4962 - precision_2: 0.9933 - recall_2: 0.8291 - val_loss: 0.1180 - val_acc: 0.4985 - val_precision_2: 0.9894 - val_recall_2: 0.8408\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1166 - acc: 0.5004 - precision_2: 0.9902 - recall_2: 0.8404 - val_loss: 0.1158 - val_acc: 0.5018 - val_precision_2: 0.9894 - val_recall_2: 0.8453\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1152 - acc: 0.5035 - precision_2: 0.9887 - recall_2: 0.8433 - val_loss: 0.1168 - val_acc: 0.4904 - val_precision_2: 0.9893 - val_recall_2: 0.8379\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1141 - acc: 0.5054 - precision_2: 0.9867 - recall_2: 0.8451 - val_loss: 0.1118 - val_acc: 0.5151 - val_precision_2: 0.9921 - val_recall_2: 0.8464\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1103 - acc: 0.5101 - precision_2: 0.9897 - recall_2: 0.8505 - val_loss: 0.1120 - val_acc: 0.5173 - val_precision_2: 0.9973 - val_recall_2: 0.8392\n",
      "Epoch 71/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1099 - acc: 0.5098 - precision_2: 0.9859 - recall_2: 0.8513 - val_loss: 0.1100 - val_acc: 0.4997 - val_precision_2: 0.9691 - val_recall_2: 0.8644\n",
      "Epoch 72/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1055 - acc: 0.5125 - precision_2: 0.9887 - recall_2: 0.8608 - val_loss: 0.1035 - val_acc: 0.5161 - val_precision_2: 0.9803 - val_recall_2: 0.8703\n",
      "Epoch 73/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1059 - acc: 0.5128 - precision_2: 0.9814 - recall_2: 0.8650 - val_loss: 0.1130 - val_acc: 0.4873 - val_precision_2: 0.9523 - val_recall_2: 0.8770\n",
      "Epoch 74/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1057 - acc: 0.5122 - precision_2: 0.9836 - recall_2: 0.8642 - val_loss: 0.0997 - val_acc: 0.5249 - val_precision_2: 0.9845 - val_recall_2: 0.8752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0988 - acc: 0.5161 - precision_2: 0.9873 - recall_2: 0.8761 - val_loss: 0.0956 - val_acc: 0.5213 - val_precision_2: 0.9794 - val_recall_2: 0.8879\n",
      "Epoch 76/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0974 - acc: 0.5132 - precision_2: 0.9844 - recall_2: 0.8806 - val_loss: 0.0939 - val_acc: 0.5183 - val_precision_2: 0.9911 - val_recall_2: 0.8827\n",
      "Epoch 77/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0945 - acc: 0.5150 - precision_2: 0.9844 - recall_2: 0.8871 - val_loss: 0.0951 - val_acc: 0.5324 - val_precision_2: 0.9862 - val_recall_2: 0.8851\n",
      "Epoch 78/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0922 - acc: 0.5141 - precision_2: 0.9804 - recall_2: 0.8950 - val_loss: 0.0973 - val_acc: 0.5249 - val_precision_2: 0.9906 - val_recall_2: 0.8771\n",
      "Epoch 79/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0925 - acc: 0.5109 - precision_2: 0.9797 - recall_2: 0.8937 - val_loss: 0.0869 - val_acc: 0.5191 - val_precision_2: 0.9918 - val_recall_2: 0.8944\n",
      "Epoch 80/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0890 - acc: 0.5150 - precision_2: 0.9775 - recall_2: 0.9002 - val_loss: 0.0864 - val_acc: 0.5185 - val_precision_2: 0.9860 - val_recall_2: 0.8989\n",
      "Epoch 81/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1032 - acc: 0.5007 - precision_2: 0.9653 - recall_2: 0.8851 - val_loss: 0.0908 - val_acc: 0.5249 - val_precision_2: 0.9949 - val_recall_2: 0.8831\n",
      "Epoch 82/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0806 - acc: 0.5131 - precision_2: 0.9840 - recall_2: 0.9128 - val_loss: 0.0792 - val_acc: 0.5196 - val_precision_2: 0.9932 - val_recall_2: 0.9099\n",
      "Epoch 83/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0799 - acc: 0.5137 - precision_2: 0.9803 - recall_2: 0.9161 - val_loss: 0.0789 - val_acc: 0.5032 - val_precision_2: 0.9542 - val_recall_2: 0.9388\n",
      "Epoch 84/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0764 - acc: 0.5152 - precision_2: 0.9805 - recall_2: 0.9226 - val_loss: 0.0740 - val_acc: 0.5302 - val_precision_2: 0.9964 - val_recall_2: 0.9140\n",
      "Epoch 85/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0725 - acc: 0.5167 - precision_2: 0.9820 - recall_2: 0.9278 - val_loss: 0.0734 - val_acc: 0.5215 - val_precision_2: 0.9912 - val_recall_2: 0.9202\n",
      "Epoch 86/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0722 - acc: 0.5146 - precision_2: 0.9799 - recall_2: 0.9288 - val_loss: 0.0720 - val_acc: 0.5211 - val_precision_2: 0.9920 - val_recall_2: 0.9211\n",
      "Epoch 87/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0664 - acc: 0.5163 - precision_2: 0.9833 - recall_2: 0.9358 - val_loss: 0.0640 - val_acc: 0.5178 - val_precision_2: 0.9870 - val_recall_2: 0.9376\n",
      "Epoch 88/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0643 - acc: 0.5169 - precision_2: 0.9822 - recall_2: 0.9375 - val_loss: 0.0684 - val_acc: 0.5309 - val_precision_2: 0.9947 - val_recall_2: 0.9240\n",
      "Epoch 89/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0689 - acc: 0.5152 - precision_2: 0.9786 - recall_2: 0.9328 - val_loss: 0.0699 - val_acc: 0.5233 - val_precision_2: 0.9972 - val_recall_2: 0.9168\n",
      "Epoch 90/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0674 - acc: 0.5151 - precision_2: 0.9785 - recall_2: 0.9329 - val_loss: 0.0658 - val_acc: 0.5026 - val_precision_2: 0.9825 - val_recall_2: 0.9317\n",
      "Epoch 91/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0597 - acc: 0.5182 - precision_2: 0.9848 - recall_2: 0.9413 - val_loss: 0.0686 - val_acc: 0.5112 - val_precision_2: 0.9321 - val_recall_2: 0.9611\n",
      "Epoch 92/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0594 - acc: 0.5206 - precision_2: 0.9820 - recall_2: 0.9432 - val_loss: 0.0569 - val_acc: 0.5061 - val_precision_2: 0.9814 - val_recall_2: 0.9459\n",
      "Epoch 93/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0562 - acc: 0.5197 - precision_2: 0.9815 - recall_2: 0.9456 - val_loss: 0.0536 - val_acc: 0.5277 - val_precision_2: 0.9935 - val_recall_2: 0.9420\n",
      "Epoch 94/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0549 - acc: 0.5223 - precision_2: 0.9844 - recall_2: 0.9464 - val_loss: 0.0534 - val_acc: 0.5133 - val_precision_2: 0.9719 - val_recall_2: 0.9556\n",
      "Epoch 95/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0523 - acc: 0.5208 - precision_2: 0.9843 - recall_2: 0.9502 - val_loss: 0.0501 - val_acc: 0.5335 - val_precision_2: 0.9935 - val_recall_2: 0.9478\n",
      "Epoch 96/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0518 - acc: 0.5220 - precision_2: 0.9838 - recall_2: 0.9497 - val_loss: 0.0493 - val_acc: 0.5268 - val_precision_2: 0.9952 - val_recall_2: 0.9456\n",
      "Epoch 97/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0482 - acc: 0.5215 - precision_2: 0.9876 - recall_2: 0.9532 - val_loss: 0.0449 - val_acc: 0.5241 - val_precision_2: 0.9876 - val_recall_2: 0.9563\n",
      "Epoch 98/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0459 - acc: 0.5242 - precision_2: 0.9861 - recall_2: 0.9561 - val_loss: 0.0470 - val_acc: 0.5317 - val_precision_2: 0.9640 - val_recall_2: 0.9664\n",
      "Epoch 99/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0455 - acc: 0.5220 - precision_2: 0.9869 - recall_2: 0.9560 - val_loss: 0.0477 - val_acc: 0.5109 - val_precision_2: 0.9734 - val_recall_2: 0.9611\n",
      "Epoch 100/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0415 - acc: 0.5218 - precision_2: 0.9874 - recall_2: 0.9622 - val_loss: 0.0466 - val_acc: 0.5360 - val_precision_2: 0.9897 - val_recall_2: 0.9541\n",
      "Epoch 101/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0403 - acc: 0.5224 - precision_2: 0.9877 - recall_2: 0.9642 - val_loss: 0.0399 - val_acc: 0.5223 - val_precision_2: 0.9826 - val_recall_2: 0.9677\n",
      "Epoch 102/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0449 - acc: 0.5207 - precision_2: 0.9832 - recall_2: 0.9601 - val_loss: 0.0390 - val_acc: 0.5182 - val_precision_2: 0.9904 - val_recall_2: 0.9638\n",
      "Epoch 103/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0396 - acc: 0.5199 - precision_2: 0.9862 - recall_2: 0.9659 - val_loss: 0.0389 - val_acc: 0.5211 - val_precision_2: 0.9946 - val_recall_2: 0.9593\n",
      "Epoch 104/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.4242 - acc: 0.4743 - precision_2: 0.8420 - recall_2: 0.6402 - val_loss: 0.3099 - val_acc: 0.4890 - val_precision_2: 0.9197 - val_recall_2: 0.6532\n",
      "Epoch 105/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2690 - acc: 0.4772 - precision_2: 0.9537 - recall_2: 0.6677 - val_loss: 0.2306 - val_acc: 0.5008 - val_precision_2: 0.9733 - val_recall_2: 0.6830\n",
      "Epoch 106/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2095 - acc: 0.4953 - precision_2: 0.9621 - recall_2: 0.7110 - val_loss: 0.1930 - val_acc: 0.5027 - val_precision_2: 0.9580 - val_recall_2: 0.7312\n",
      "Epoch 107/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1755 - acc: 0.5003 - precision_2: 0.9229 - recall_2: 0.7823 - val_loss: 0.1646 - val_acc: 0.5063 - val_precision_2: 0.8735 - val_recall_2: 0.8434\n",
      "Epoch 108/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1434 - acc: 0.5855 - precision_2: 0.9219 - recall_2: 0.8409 - val_loss: 0.1288 - val_acc: 0.6060 - val_precision_2: 0.9321 - val_recall_2: 0.8658\n",
      "Epoch 109/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1164 - acc: 0.6019 - precision_2: 0.9644 - recall_2: 0.8725 - val_loss: 0.1030 - val_acc: 0.5489 - val_precision_2: 0.9727 - val_recall_2: 0.8889\n",
      "Epoch 110/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0975 - acc: 0.5635 - precision_2: 0.9730 - recall_2: 0.8978 - val_loss: 0.0907 - val_acc: 0.5503 - val_precision_2: 0.9631 - val_recall_2: 0.9095\n",
      "Epoch 111/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0869 - acc: 0.5587 - precision_2: 0.9721 - recall_2: 0.9117 - val_loss: 0.0806 - val_acc: 0.5477 - val_precision_2: 0.9710 - val_recall_2: 0.9177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0789 - acc: 0.5522 - precision_2: 0.9756 - recall_2: 0.9211 - val_loss: 0.0745 - val_acc: 0.5534 - val_precision_2: 0.9726 - val_recall_2: 0.9274\n",
      "Epoch 113/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0745 - acc: 0.5523 - precision_2: 0.9750 - recall_2: 0.9303 - val_loss: 0.0677 - val_acc: 0.5491 - val_precision_2: 0.9774 - val_recall_2: 0.9415\n",
      "Epoch 114/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0668 - acc: 0.5509 - precision_2: 0.9789 - recall_2: 0.9424 - val_loss: 0.0630 - val_acc: 0.5538 - val_precision_2: 0.9784 - val_recall_2: 0.9479\n",
      "Epoch 115/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0619 - acc: 0.5530 - precision_2: 0.9804 - recall_2: 0.9474 - val_loss: 0.0598 - val_acc: 0.5577 - val_precision_2: 0.9888 - val_recall_2: 0.9449\n",
      "Epoch 116/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0583 - acc: 0.5559 - precision_2: 0.9818 - recall_2: 0.9519 - val_loss: 0.0543 - val_acc: 0.5587 - val_precision_2: 0.9860 - val_recall_2: 0.9557\n",
      "Epoch 117/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0580 - acc: 0.5568 - precision_2: 0.9819 - recall_2: 0.9535 - val_loss: 0.0524 - val_acc: 0.5605 - val_precision_2: 0.9858 - val_recall_2: 0.9564\n",
      "Epoch 118/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0521 - acc: 0.5602 - precision_2: 0.9863 - recall_2: 0.9596 - val_loss: 0.0468 - val_acc: 0.5643 - val_precision_2: 0.9893 - val_recall_2: 0.9650\n",
      "Epoch 119/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0474 - acc: 0.5706 - precision_2: 0.9863 - recall_2: 0.9668 - val_loss: 0.0443 - val_acc: 0.5719 - val_precision_2: 0.9797 - val_recall_2: 0.9743\n",
      "Epoch 120/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0408 - acc: 0.5755 - precision_2: 0.9877 - recall_2: 0.9734 - val_loss: 0.0416 - val_acc: 0.5779 - val_precision_2: 0.9858 - val_recall_2: 0.9722\n",
      "Epoch 121/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0383 - acc: 0.5761 - precision_2: 0.9888 - recall_2: 0.9753 - val_loss: 0.0377 - val_acc: 0.5784 - val_precision_2: 0.9946 - val_recall_2: 0.9717\n",
      "Epoch 122/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0352 - acc: 0.5762 - precision_2: 0.9898 - recall_2: 0.9769 - val_loss: 0.0354 - val_acc: 0.5767 - val_precision_2: 0.9925 - val_recall_2: 0.9748\n",
      "Epoch 123/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0334 - acc: 0.5761 - precision_2: 0.9898 - recall_2: 0.9780 - val_loss: 0.0332 - val_acc: 0.5801 - val_precision_2: 0.9889 - val_recall_2: 0.9789\n",
      "Epoch 124/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0327 - acc: 0.5758 - precision_2: 0.9900 - recall_2: 0.9786 - val_loss: 0.0359 - val_acc: 0.5801 - val_precision_2: 0.9957 - val_recall_2: 0.9697\n",
      "Epoch 125/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0311 - acc: 0.5769 - precision_2: 0.9911 - recall_2: 0.9790 - val_loss: 0.0308 - val_acc: 0.5787 - val_precision_2: 0.9933 - val_recall_2: 0.9774\n",
      "Epoch 126/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0289 - acc: 0.5771 - precision_2: 0.9914 - recall_2: 0.9809 - val_loss: 0.0317 - val_acc: 0.5806 - val_precision_2: 0.9926 - val_recall_2: 0.9748\n",
      "Epoch 127/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0297 - acc: 0.5776 - precision_2: 0.9912 - recall_2: 0.9799 - val_loss: 0.0272 - val_acc: 0.5789 - val_precision_2: 0.9910 - val_recall_2: 0.9829\n",
      "Epoch 128/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0273 - acc: 0.5771 - precision_2: 0.9923 - recall_2: 0.9821 - val_loss: 0.0295 - val_acc: 0.5813 - val_precision_2: 0.9963 - val_recall_2: 0.9757\n",
      "Epoch 129/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0272 - acc: 0.5780 - precision_2: 0.9921 - recall_2: 0.9814 - val_loss: 0.0270 - val_acc: 0.5785 - val_precision_2: 0.9944 - val_recall_2: 0.9801\n",
      "Epoch 130/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0259 - acc: 0.5777 - precision_2: 0.9927 - recall_2: 0.9828 - val_loss: 0.0248 - val_acc: 0.5803 - val_precision_2: 0.9885 - val_recall_2: 0.9872\n",
      "Epoch 131/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0252 - acc: 0.5771 - precision_2: 0.9927 - recall_2: 0.9834 - val_loss: 0.0252 - val_acc: 0.5817 - val_precision_2: 0.9974 - val_recall_2: 0.9797\n",
      "Epoch 132/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0238 - acc: 0.5777 - precision_2: 0.9935 - recall_2: 0.9845 - val_loss: 0.0228 - val_acc: 0.5804 - val_precision_2: 0.9935 - val_recall_2: 0.9851\n",
      "Epoch 133/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0229 - acc: 0.5779 - precision_2: 0.9938 - recall_2: 0.9850 - val_loss: 0.0245 - val_acc: 0.5823 - val_precision_2: 0.9964 - val_recall_2: 0.9803\n",
      "Epoch 134/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0229 - acc: 0.5788 - precision_2: 0.9943 - recall_2: 0.9848 - val_loss: 0.0268 - val_acc: 0.5803 - val_precision_2: 0.9739 - val_recall_2: 0.9916\n",
      "Epoch 135/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0266 - acc: 0.5776 - precision_2: 0.9913 - recall_2: 0.9813 - val_loss: 0.0233 - val_acc: 0.5806 - val_precision_2: 0.9971 - val_recall_2: 0.9805\n",
      "Epoch 136/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0211 - acc: 0.5776 - precision_2: 0.9949 - recall_2: 0.9861 - val_loss: 0.0230 - val_acc: 0.5812 - val_precision_2: 0.9863 - val_recall_2: 0.9900\n",
      "Epoch 137/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0206 - acc: 0.5785 - precision_2: 0.9948 - recall_2: 0.9864 - val_loss: 0.0222 - val_acc: 0.5810 - val_precision_2: 0.9948 - val_recall_2: 0.9830\n",
      "Epoch 138/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0205 - acc: 0.5783 - precision_2: 0.9945 - recall_2: 0.9865 - val_loss: 0.0251 - val_acc: 0.5829 - val_precision_2: 0.9970 - val_recall_2: 0.9793\n",
      "Epoch 139/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0301 - acc: 0.5758 - precision_2: 0.9890 - recall_2: 0.9792 - val_loss: 0.0237 - val_acc: 0.5834 - val_precision_2: 0.9972 - val_recall_2: 0.9795\n",
      "Epoch 140/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0197 - acc: 0.5783 - precision_2: 0.9950 - recall_2: 0.9863 - val_loss: 0.0211 - val_acc: 0.5815 - val_precision_2: 0.9975 - val_recall_2: 0.9821\n",
      "Epoch 141/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0195 - acc: 0.5780 - precision_2: 0.9946 - recall_2: 0.9872 - val_loss: 0.0213 - val_acc: 0.5805 - val_precision_2: 0.9987 - val_recall_2: 0.9811\n",
      "Epoch 142/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0192 - acc: 0.5771 - precision_2: 0.9955 - recall_2: 0.9867 - val_loss: 0.0192 - val_acc: 0.5811 - val_precision_2: 0.9935 - val_recall_2: 0.9888\n",
      "Epoch 143/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0179 - acc: 0.5766 - precision_2: 0.9953 - recall_2: 0.9883 - val_loss: 0.0197 - val_acc: 0.5827 - val_precision_2: 0.9988 - val_recall_2: 0.9820\n",
      "Epoch 144/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0175 - acc: 0.5775 - precision_2: 0.9960 - recall_2: 0.9884 - val_loss: 0.0169 - val_acc: 0.5827 - val_precision_2: 0.9932 - val_recall_2: 0.9907\n",
      "Epoch 145/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0169 - acc: 0.5781 - precision_2: 0.9957 - recall_2: 0.9891 - val_loss: 0.0191 - val_acc: 0.5827 - val_precision_2: 0.9933 - val_recall_2: 0.9873\n",
      "Epoch 146/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0169 - acc: 0.5770 - precision_2: 0.9953 - recall_2: 0.9893 - val_loss: 0.0162 - val_acc: 0.5818 - val_precision_2: 0.9943 - val_recall_2: 0.9911\n",
      "Epoch 147/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0166 - acc: 0.5773 - precision_2: 0.9956 - recall_2: 0.9889 - val_loss: 0.0198 - val_acc: 0.5804 - val_precision_2: 0.9800 - val_recall_2: 0.9937\n",
      "Epoch 148/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0162 - acc: 0.5774 - precision_2: 0.9954 - recall_2: 0.9893 - val_loss: 0.0170 - val_acc: 0.5819 - val_precision_2: 0.9938 - val_recall_2: 0.9894\n",
      "Epoch 149/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0150 - acc: 0.5778 - precision_2: 0.9962 - recall_2: 0.9904 - val_loss: 0.0156 - val_acc: 0.5800 - val_precision_2: 0.9981 - val_recall_2: 0.9875\n",
      "Epoch 150/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0146 - acc: 0.5775 - precision_2: 0.9966 - recall_2: 0.9908 - val_loss: 0.0178 - val_acc: 0.5794 - val_precision_2: 0.9971 - val_recall_2: 0.9857\n",
      "Epoch 151/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0152 - acc: 0.5761 - precision_2: 0.9962 - recall_2: 0.9904 - val_loss: 0.0151 - val_acc: 0.5791 - val_precision_2: 0.9940 - val_recall_2: 0.9911\n",
      "Epoch 152/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0151 - acc: 0.5769 - precision_2: 0.9960 - recall_2: 0.9902 - val_loss: 0.0151 - val_acc: 0.5791 - val_precision_2: 0.9977 - val_recall_2: 0.9887\n",
      "Epoch 153/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0141 - acc: 0.5764 - precision_2: 0.9964 - recall_2: 0.9909 - val_loss: 0.0138 - val_acc: 0.5809 - val_precision_2: 0.9961 - val_recall_2: 0.9916\n",
      "Epoch 154/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0140 - acc: 0.5767 - precision_2: 0.9965 - recall_2: 0.9910 - val_loss: 0.0159 - val_acc: 0.5821 - val_precision_2: 0.9982 - val_recall_2: 0.9870\n",
      "Epoch 155/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0137 - acc: 0.5760 - precision_2: 0.9967 - recall_2: 0.9911 - val_loss: 0.0147 - val_acc: 0.5780 - val_precision_2: 0.9970 - val_recall_2: 0.9893\n",
      "Epoch 156/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0137 - acc: 0.5751 - precision_2: 0.9963 - recall_2: 0.9912 - val_loss: 0.0143 - val_acc: 0.5775 - val_precision_2: 0.9990 - val_recall_2: 0.9879\n",
      "Epoch 157/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0133 - acc: 0.5743 - precision_2: 0.9968 - recall_2: 0.9912 - val_loss: 0.0133 - val_acc: 0.5774 - val_precision_2: 0.9944 - val_recall_2: 0.9927\n",
      "Epoch 158/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0128 - acc: 0.5730 - precision_2: 0.9973 - recall_2: 0.9915 - val_loss: 0.0147 - val_acc: 0.5771 - val_precision_2: 0.9905 - val_recall_2: 0.9936\n",
      "Epoch 159/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0124 - acc: 0.5728 - precision_2: 0.9970 - recall_2: 0.9920 - val_loss: 0.0137 - val_acc: 0.5738 - val_precision_2: 0.9944 - val_recall_2: 0.9923\n",
      "Epoch 160/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0119 - acc: 0.5711 - precision_2: 0.9973 - recall_2: 0.9923 - val_loss: 0.0134 - val_acc: 0.5792 - val_precision_2: 0.9950 - val_recall_2: 0.9921\n",
      "Epoch 161/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0149 - acc: 0.5707 - precision_2: 0.9952 - recall_2: 0.9903 - val_loss: 0.0129 - val_acc: 0.5737 - val_precision_2: 0.9973 - val_recall_2: 0.9905\n",
      "Epoch 162/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0139 - acc: 0.5693 - precision_2: 0.9963 - recall_2: 0.9903 - val_loss: 0.0139 - val_acc: 0.5748 - val_precision_2: 0.9920 - val_recall_2: 0.9928\n",
      "Epoch 163/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0124 - acc: 0.5724 - precision_2: 0.9971 - recall_2: 0.9923 - val_loss: 0.0120 - val_acc: 0.5735 - val_precision_2: 0.9977 - val_recall_2: 0.9912\n",
      "Epoch 164/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0124 - acc: 0.5698 - precision_2: 0.9969 - recall_2: 0.9920 - val_loss: 0.0189 - val_acc: 0.5732 - val_precision_2: 0.9991 - val_recall_2: 0.9832\n",
      "Epoch 165/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0119 - acc: 0.5700 - precision_2: 0.9969 - recall_2: 0.9923 - val_loss: 0.0122 - val_acc: 0.5736 - val_precision_2: 0.9974 - val_recall_2: 0.9912\n",
      "Epoch 166/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0106 - acc: 0.5689 - precision_2: 0.9976 - recall_2: 0.9932 - val_loss: 0.0112 - val_acc: 0.5695 - val_precision_2: 0.9971 - val_recall_2: 0.9925\n",
      "Epoch 167/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0107 - acc: 0.5640 - precision_2: 0.9972 - recall_2: 0.9930 - val_loss: 0.0128 - val_acc: 0.5687 - val_precision_2: 0.9974 - val_recall_2: 0.9904\n",
      "Epoch 168/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0120 - acc: 0.5620 - precision_2: 0.9965 - recall_2: 0.9919 - val_loss: 0.0154 - val_acc: 0.5616 - val_precision_2: 0.9883 - val_recall_2: 0.9933\n",
      "Epoch 169/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0112 - acc: 0.5586 - precision_2: 0.9969 - recall_2: 0.9929 - val_loss: 0.0120 - val_acc: 0.5663 - val_precision_2: 0.9976 - val_recall_2: 0.9915\n",
      "Epoch 170/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0124 - acc: 0.5618 - precision_2: 0.9958 - recall_2: 0.9918 - val_loss: 0.0122 - val_acc: 0.5691 - val_precision_2: 0.9965 - val_recall_2: 0.9912\n",
      "Epoch 171/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0105 - acc: 0.5605 - precision_2: 0.9971 - recall_2: 0.9931 - val_loss: 0.0108 - val_acc: 0.5659 - val_precision_2: 0.9963 - val_recall_2: 0.9932\n",
      "Epoch 172/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0091 - acc: 0.5571 - precision_2: 0.9981 - recall_2: 0.9941 - val_loss: 0.0191 - val_acc: 0.5604 - val_precision_2: 0.9789 - val_recall_2: 0.9957\n",
      "Epoch 173/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0113 - acc: 0.5571 - precision_2: 0.9970 - recall_2: 0.9925 - val_loss: 0.0112 - val_acc: 0.5557 - val_precision_2: 0.9961 - val_recall_2: 0.9925\n",
      "Epoch 174/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0102 - acc: 0.5529 - precision_2: 0.9971 - recall_2: 0.9931 - val_loss: 0.0177 - val_acc: 0.5538 - val_precision_2: 0.9996 - val_recall_2: 0.9828\n",
      "Epoch 175/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0131 - acc: 0.5559 - precision_2: 0.9958 - recall_2: 0.9913 - val_loss: 0.0147 - val_acc: 0.5507 - val_precision_2: 0.9991 - val_recall_2: 0.9866\n",
      "Epoch 176/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0099 - acc: 0.5516 - precision_2: 0.9976 - recall_2: 0.9934 - val_loss: 0.0106 - val_acc: 0.5551 - val_precision_2: 0.9972 - val_recall_2: 0.9927\n",
      "Epoch 177/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0084 - acc: 0.5476 - precision_2: 0.9983 - recall_2: 0.9947 - val_loss: 0.0102 - val_acc: 0.5498 - val_precision_2: 0.9951 - val_recall_2: 0.9945\n",
      "Epoch 178/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0081 - acc: 0.5465 - precision_2: 0.9981 - recall_2: 0.9948 - val_loss: 0.0120 - val_acc: 0.5464 - val_precision_2: 0.9994 - val_recall_2: 0.9898\n",
      "Epoch 179/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0085 - acc: 0.5468 - precision_2: 0.9982 - recall_2: 0.9945 - val_loss: 0.0114 - val_acc: 0.5402 - val_precision_2: 0.9942 - val_recall_2: 0.9940\n",
      "Epoch 180/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0104 - acc: 0.5458 - precision_2: 0.9969 - recall_2: 0.9934 - val_loss: 0.0115 - val_acc: 0.5468 - val_precision_2: 0.9994 - val_recall_2: 0.9901\n",
      "Epoch 181/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0091 - acc: 0.5429 - precision_2: 0.9977 - recall_2: 0.9940 - val_loss: 0.0134 - val_acc: 0.5412 - val_precision_2: 0.9924 - val_recall_2: 0.9934\n",
      "Epoch 182/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0079 - acc: 0.5423 - precision_2: 0.9983 - recall_2: 0.9949 - val_loss: 0.0099 - val_acc: 0.5391 - val_precision_2: 0.9960 - val_recall_2: 0.9943\n",
      "Epoch 183/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0088 - acc: 0.5377 - precision_2: 0.9977 - recall_2: 0.9942 - val_loss: 0.0125 - val_acc: 0.5397 - val_precision_2: 0.9992 - val_recall_2: 0.9889\n",
      "Epoch 184/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0077 - acc: 0.5415 - precision_2: 0.9984 - recall_2: 0.9950 - val_loss: 0.0105 - val_acc: 0.5329 - val_precision_2: 0.9931 - val_recall_2: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0076 - acc: 0.5379 - precision_2: 0.9983 - recall_2: 0.9953 - val_loss: 0.0095 - val_acc: 0.5409 - val_precision_2: 0.9968 - val_recall_2: 0.9940\n",
      "Epoch 186/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0077 - acc: 0.5405 - precision_2: 0.9982 - recall_2: 0.9950 - val_loss: 0.0097 - val_acc: 0.5410 - val_precision_2: 0.9990 - val_recall_2: 0.9927\n",
      "Epoch 187/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0076 - acc: 0.5372 - precision_2: 0.9985 - recall_2: 0.9951 - val_loss: 0.0090 - val_acc: 0.5395 - val_precision_2: 0.9989 - val_recall_2: 0.9927\n",
      "Epoch 188/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0067 - acc: 0.5383 - precision_2: 0.9987 - recall_2: 0.9958 - val_loss: 0.0133 - val_acc: 0.5433 - val_precision_2: 0.9917 - val_recall_2: 0.9933\n",
      "Epoch 189/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0112 - acc: 0.5395 - precision_2: 0.9969 - recall_2: 0.9926 - val_loss: 0.0167 - val_acc: 0.5423 - val_precision_2: 0.9854 - val_recall_2: 0.9942\n",
      "Epoch 190/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0103 - acc: 0.5406 - precision_2: 0.9970 - recall_2: 0.9935 - val_loss: 0.0099 - val_acc: 0.5346 - val_precision_2: 0.9974 - val_recall_2: 0.9929\n",
      "Epoch 191/200\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0085 - acc: 0.5344 - precision_2: 0.9978 - recall_2: 0.9945 - val_loss: 0.0087 - val_acc: 0.5472 - val_precision_2: 0.9964 - val_recall_2: 0.9944\n",
      "Epoch 192/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0095 - acc: 0.5372 - precision_2: 0.9973 - recall_2: 0.9933 - val_loss: 0.0185 - val_acc: 0.5380 - val_precision_2: 0.9982 - val_recall_2: 0.9844\n",
      "Epoch 193/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0090 - acc: 0.5345 - precision_2: 0.9976 - recall_2: 0.9939 - val_loss: 0.0083 - val_acc: 0.5323 - val_precision_2: 0.9985 - val_recall_2: 0.9940\n",
      "Epoch 194/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0075 - acc: 0.5313 - precision_2: 0.9979 - recall_2: 0.9947 - val_loss: 0.0085 - val_acc: 0.5327 - val_precision_2: 0.9977 - val_recall_2: 0.9944\n",
      "Epoch 195/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0072 - acc: 0.5286 - precision_2: 0.9984 - recall_2: 0.9950 - val_loss: 0.0089 - val_acc: 0.5301 - val_precision_2: 0.9994 - val_recall_2: 0.9925\n",
      "Epoch 196/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0065 - acc: 0.5309 - precision_2: 0.9988 - recall_2: 0.9957 - val_loss: 0.0079 - val_acc: 0.5305 - val_precision_2: 0.9966 - val_recall_2: 0.9960\n",
      "Epoch 197/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0061 - acc: 0.5312 - precision_2: 0.9988 - recall_2: 0.9961 - val_loss: 0.0093 - val_acc: 0.5309 - val_precision_2: 0.9993 - val_recall_2: 0.9926\n",
      "Epoch 198/200\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0062 - acc: 0.5305 - precision_2: 0.9988 - recall_2: 0.9960 - val_loss: 0.0075 - val_acc: 0.5318 - val_precision_2: 0.9970 - val_recall_2: 0.9958\n",
      "Epoch 199/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0063 - acc: 0.5307 - precision_2: 0.9987 - recall_2: 0.9959 - val_loss: 0.0090 - val_acc: 0.5273 - val_precision_2: 0.9949 - val_recall_2: 0.9958\n",
      "Epoch 200/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0080 - acc: 0.5274 - precision_2: 0.9977 - recall_2: 0.9947 - val_loss: 0.0087 - val_acc: 0.5312 - val_precision_2: 0.9982 - val_recall_2: 0.9936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "miniModel = Sequential()\n",
    "miniModel.add(Input(shape=(None,3)))\n",
    "miniModel.add(Dense(10))\n",
    "miniModel.add(Dense(10))\n",
    "miniModel.add(LSTM(64, return_sequences=True))\n",
    "# miniModel.add(LSTM(32, return_sequences=True))\n",
    "# miniModel.add(LSTM(16, return_sequences=True))\n",
    "miniModel.add(LSTM(8))\n",
    "miniModel.add(Dense(y_train.shape[-1], 'sigmoid'))\n",
    "miniModel.compile('adam', loss='binary_crossentropy', metrics=['acc',tf.keras.metrics.Precision(thresholds=0.4),tf.keras.metrics.Recall(thresholds=0.4)])\n",
    "history = miniModel.fit(X_train, y_train, batch_size=512, epochs=200, validation_data=(X_valid, y_valid))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_valid = miniModel.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    fpr, tpr, threshold = roc_curve(y_valid.numpy()[:,i],p_valid[:,i])\n",
    "    plt.plot(fpr, tpr, 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71322566 0.5001814  0.48774964 0.03192484 0.03667786] tf.Tensor([1. 1. 0. 0. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.06034129 0.06585459 0.19471435 0.06835146 0.01269905] tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.20220664 0.2979014  0.26602855 0.906237   0.01835955] tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.6115387  0.5046338  0.36417273 0.0350249  0.02694007] tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.17834157 0.26735312 0.23656024 0.8718697  0.02045879] tf.Tensor([0. 1. 1. 1. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.71569145 0.50135106 0.49034566 0.0320709  0.03777572] tf.Tensor([1. 1. 0. 0. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.62485117 0.6227815  0.34706    0.05000204 0.98398596] tf.Tensor([1. 1. 0. 0. 1.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.5255484  0.5239653  0.27535173 0.03921982 0.0204173 ] tf.Tensor([1. 1. 0. 0. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.42145592 0.41403216 0.33277994 0.06149404 0.9786078 ] tf.Tensor([1. 0. 0. 0. 1.], shape=(5,), dtype=float32)\n",
      "###########################################################\n",
      "[0.19737378 0.29977128 0.25421816 0.902853   0.01966858] tf.Tensor([0. 1. 0. 1. 0.], shape=(5,), dtype=float32)\n",
      "###########################################################\n"
     ]
    }
   ],
   "source": [
    "for i in random.sample(range(0, 15000), 10):\n",
    "    print(p_valid[i], y_valid[i])\n",
    "    print(\"###########################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 4s 179ms/step - loss: 0.6881 - acc: 0.1701 - val_loss: 0.6909 - val_acc: 0.4826\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6794 - acc: 0.3030 - val_loss: 0.6887 - val_acc: 0.1432\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6753 - acc: 0.1546 - val_loss: 0.6866 - val_acc: 0.1102\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6732 - acc: 0.1186 - val_loss: 0.6844 - val_acc: 0.1102\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6712 - acc: 0.1605 - val_loss: 0.6824 - val_acc: 0.1863\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6694 - acc: 0.1840 - val_loss: 0.6803 - val_acc: 0.1863\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6677 - acc: 0.1871 - val_loss: 0.6783 - val_acc: 0.1863\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6657 - acc: 0.1686 - val_loss: 0.6762 - val_acc: 0.1863\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6639 - acc: 0.1491 - val_loss: 0.6742 - val_acc: 0.1863\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6622 - acc: 0.1831 - val_loss: 0.6723 - val_acc: 0.1863\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6605 - acc: 0.1919 - val_loss: 0.6703 - val_acc: 0.1863\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6588 - acc: 0.2641 - val_loss: 0.6684 - val_acc: 0.4826\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6570 - acc: 0.2436 - val_loss: 0.6665 - val_acc: 0.1863\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6553 - acc: 0.3552 - val_loss: 0.6646 - val_acc: 0.4826\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6537 - acc: 0.4558 - val_loss: 0.6628 - val_acc: 0.4826\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6521 - acc: 0.4709 - val_loss: 0.6610 - val_acc: 0.4826\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6505 - acc: 0.4621 - val_loss: 0.6592 - val_acc: 0.4826\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6489 - acc: 0.4490 - val_loss: 0.6574 - val_acc: 0.4826\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6473 - acc: 0.4685 - val_loss: 0.6557 - val_acc: 0.4826\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6458 - acc: 0.4687 - val_loss: 0.6539 - val_acc: 0.4826\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6443 - acc: 0.4497 - val_loss: 0.6523 - val_acc: 0.4826\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6428 - acc: 0.4497 - val_loss: 0.6506 - val_acc: 0.4826\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6414 - acc: 0.4578 - val_loss: 0.6489 - val_acc: 0.4826\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6398 - acc: 0.4556 - val_loss: 0.6473 - val_acc: 0.4826\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6386 - acc: 0.4580 - val_loss: 0.6457 - val_acc: 0.4826\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6371 - acc: 0.4561 - val_loss: 0.6442 - val_acc: 0.4826\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6355 - acc: 0.4530 - val_loss: 0.6426 - val_acc: 0.4826\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6343 - acc: 0.4499 - val_loss: 0.6411 - val_acc: 0.4826\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6329 - acc: 0.4501 - val_loss: 0.6396 - val_acc: 0.4826\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6316 - acc: 0.4744 - val_loss: 0.6381 - val_acc: 0.4826\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6304 - acc: 0.4599 - val_loss: 0.6367 - val_acc: 0.4826\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6291 - acc: 0.4487 - val_loss: 0.6352 - val_acc: 0.4826\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6278 - acc: 0.4493 - val_loss: 0.6338 - val_acc: 0.4826\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6265 - acc: 0.4541 - val_loss: 0.6324 - val_acc: 0.4826\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6254 - acc: 0.4616 - val_loss: 0.6310 - val_acc: 0.4826\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6240 - acc: 0.4619 - val_loss: 0.6297 - val_acc: 0.4826\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6230 - acc: 0.4527 - val_loss: 0.6284 - val_acc: 0.4826\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6218 - acc: 0.4540 - val_loss: 0.6271 - val_acc: 0.4826\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6207 - acc: 0.4511 - val_loss: 0.6258 - val_acc: 0.4826\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6195 - acc: 0.4519 - val_loss: 0.6245 - val_acc: 0.4826\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6184 - acc: 0.4497 - val_loss: 0.6233 - val_acc: 0.4826\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6174 - acc: 0.4545 - val_loss: 0.6221 - val_acc: 0.4826\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6162 - acc: 0.4543 - val_loss: 0.6209 - val_acc: 0.4826\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6153 - acc: 0.4543 - val_loss: 0.6197 - val_acc: 0.4826\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6141 - acc: 0.4595 - val_loss: 0.6185 - val_acc: 0.4826\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6131 - acc: 0.4492 - val_loss: 0.6174 - val_acc: 0.4826\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6121 - acc: 0.4495 - val_loss: 0.6162 - val_acc: 0.4826\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.6111 - acc: 0.4541 - val_loss: 0.6151 - val_acc: 0.4826\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6102 - acc: 0.4575 - val_loss: 0.6140 - val_acc: 0.4826\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6092 - acc: 0.4513 - val_loss: 0.6130 - val_acc: 0.4826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom(x):\n",
    "#     tf.print(x[1])\n",
    "    return tf.gather_nd(x[0],x[1])\n",
    "inp = Input(shape=(None,3))\n",
    "dense = Dense(10)(inp)\n",
    "lstm = LSTM(64, return_sequences=True)(inp)\n",
    "lstm = LSTM(32, return_sequences=True)(lstm)\n",
    "lstm = LSTM(16, return_sequences=True)(lstm)\n",
    "inp_lengths = Input(shape=(2), dtype=tf.int32)\n",
    "lmbda = Lambda(custom)((lstm, inp_lengths))\n",
    "final = Dense(y_train.shape[-1], 'sigmoid')(lmbda)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inp, inp_lengths], outputs=[final])\n",
    "model.compile('adam', loss='binary_crossentropy', metrics='acc')\n",
    "\n",
    "history = model.fit([X_train, lengths_train], y_train, batch_size=512, epochs=200, validation_data=([X_valid, lengths_valid], y_valid))\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([35000, 59, 3]), TensorShape([35000, 5]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cls, signals):\n",
    "    X_train_l, y_train_l = tf.gather(X_train, signals, axis=2), tf.gather(y_train, cls, axis=1)\n",
    "    X_valid_l, y_valid_l = tf.gather(X_valid, signals, axis=2), tf.gather(y_valid, cls, axis=1)\n",
    "    miniModel = Sequential()\n",
    "    miniModel.add(Input(shape=(None,len(signals))))\n",
    "    miniModel.add(Dense(10))\n",
    "    miniModel.add(Dense(10))\n",
    "    miniModel.add(LSTM(64, return_sequences=True))\n",
    "    # miniModel.add(LSTM(32, return_sequences=True))\n",
    "    # miniModel.add(LSTM(16, return_sequences=True))\n",
    "    miniModel.add(LSTM(8))\n",
    "    miniModel.add(Dense(1, 'sigmoid'))\n",
    "    miniModel.compile('adam', loss='binary_crossentropy', metrics=['acc',tf.keras.metrics.Precision(thresholds=0.4, name=\"precision\"),tf.keras.metrics.Recall(thresholds=0.4, name= \"recall\")])\n",
    "    history = miniModel.fit(X_train_l, y_train_l, batch_size=512, epochs=80, validation_data=(X_valid_l, y_valid_l))\n",
    "    precision = history.history[\"val_precision\"][-1]\n",
    "    recall = history.history[\"val_recall\"][-1]\n",
    "    return (cls,signals, miniModel, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################\n",
      "0 (0,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 27ms/step - loss: 0.5809 - acc: 0.7406 - precision: 0.2498 - recall: 0.1265 - val_loss: 0.5595 - val_acc: 0.7526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5647 - acc: 0.7465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5593 - val_acc: 0.7526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5659 - acc: 0.7465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5588 - val_acc: 0.7526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5548 - acc: 0.7465 - precision: 0.2857 - recall: 2.2540e-04 - val_loss: 0.5424 - val_acc: 0.7526 - val_precision: 0.3913 - val_recall: 0.2026\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5155 - acc: 0.7465 - precision: 0.4270 - recall: 0.2348 - val_loss: 0.4843 - val_acc: 0.7526 - val_precision: 0.4318 - val_recall: 0.8639\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4862 - acc: 0.7308 - precision: 0.4434 - recall: 0.6432 - val_loss: 0.4805 - val_acc: 0.7526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3995 - acc: 0.7681 - precision: 0.5305 - recall: 0.7175 - val_loss: 0.4586 - val_acc: 0.7183 - val_precision: 0.4715 - val_recall: 0.6653\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3397 - acc: 0.8144 - precision: 0.5414 - recall: 0.9219 - val_loss: 0.2574 - val_acc: 0.9010 - val_precision: 0.5679 - val_recall: 0.9811\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2215 - acc: 0.9217 - precision: 0.7239 - recall: 0.8119 - val_loss: 0.1769 - val_acc: 0.9337 - val_precision: 0.9746 - val_recall: 0.7435\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3231 - acc: 0.8751 - precision: 0.8924 - recall: 0.5757 - val_loss: 0.2514 - val_acc: 0.9223 - val_precision: 0.9259 - val_recall: 0.7176\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2091 - acc: 0.9282 - precision: 0.9585 - recall: 0.7400 - val_loss: 0.1810 - val_acc: 0.9350 - val_precision: 0.9830 - val_recall: 0.7483\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1795 - acc: 0.9329 - precision: 0.9907 - recall: 0.7415 - val_loss: 0.1689 - val_acc: 0.9369 - val_precision: 0.9950 - val_recall: 0.7489\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1701 - acc: 0.9336 - precision: 0.9937 - recall: 0.7420 - val_loss: 0.1611 - val_acc: 0.9372 - val_precision: 0.9953 - val_recall: 0.7483\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1638 - acc: 0.9338 - precision: 0.9962 - recall: 0.7423 - val_loss: 0.1554 - val_acc: 0.9373 - val_precision: 0.9964 - val_recall: 0.7483\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1581 - acc: 0.9342 - precision: 0.9965 - recall: 0.7426 - val_loss: 0.1497 - val_acc: 0.9374 - val_precision: 0.9986 - val_recall: 0.7491\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1498 - acc: 0.9344 - precision: 0.9979 - recall: 0.7426 - val_loss: 0.1373 - val_acc: 0.9377 - val_precision: 0.9975 - val_recall: 0.7494\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1311 - acc: 0.9344 - precision: 0.9969 - recall: 0.7719 - val_loss: 0.1095 - val_acc: 0.9378 - val_precision: 0.9902 - val_recall: 0.8998\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.0932 - acc: 0.9720 - precision: 0.9689 - recall: 0.9468 - val_loss: 0.0700 - val_acc: 0.9909 - val_precision: 0.9835 - val_recall: 0.9776\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0662 - acc: 0.9883 - precision: 0.9767 - recall: 0.9745 - val_loss: 0.0572 - val_acc: 0.9889 - val_precision: 0.9939 - val_recall: 0.9647\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6093 - acc: 0.8337 - precision: 0.6745 - recall: 0.4811 - val_loss: 0.5670 - val_acc: 0.7532 - val_precision: 0.5977 - val_recall: 0.0420\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5556 - acc: 0.7478 - precision: 0.6929 - recall: 0.0536 - val_loss: 0.5401 - val_acc: 0.7597 - val_precision: 0.6265 - val_recall: 0.1121\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5228 - acc: 0.7665 - precision: 0.6014 - recall: 0.2102 - val_loss: 0.4637 - val_acc: 0.7659 - val_precision: 0.5446 - val_recall: 0.4476\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4707 - acc: 0.8109 - precision: 0.6639 - recall: 0.4945 - val_loss: 0.5956 - val_acc: 0.7526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5606 - acc: 0.7466 - precision: 0.9630 - recall: 0.0176 - val_loss: 0.5409 - val_acc: 0.7536 - val_precision: 0.9696 - val_recall: 0.0687\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5284 - acc: 0.7691 - precision: 0.9281 - recall: 0.1527 - val_loss: 0.4991 - val_acc: 0.7959 - val_precision: 0.8500 - val_recall: 0.2153\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.4696 - acc: 0.8035 - precision: 0.6724 - recall: 0.4202 - val_loss: 0.4908 - val_acc: 0.7973 - val_precision: 0.7587 - val_recall: 0.3102\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.2522 - acc: 0.9042 - precision: 0.8111 - recall: 0.7874 - val_loss: 0.0786 - val_acc: 0.9869 - val_precision: 0.9764 - val_recall: 0.9690\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0594 - acc: 0.9898 - precision: 0.9927 - recall: 0.9681 - val_loss: 0.0479 - val_acc: 0.9914 - val_precision: 0.9994 - val_recall: 0.9687\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0381 - acc: 0.9939 - precision: 0.9963 - recall: 0.9802 - val_loss: 0.0561 - val_acc: 0.9829 - val_precision: 0.9313 - val_recall: 0.9941\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0681 - acc: 0.9834 - precision: 0.9812 - recall: 0.9526 - val_loss: 0.1050 - val_acc: 0.9684 - val_precision: 0.8862 - val_recall: 0.9860\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0421 - acc: 0.9926 - precision: 0.9964 - recall: 0.9748 - val_loss: 0.0274 - val_acc: 0.9956 - val_precision: 1.0000 - val_recall: 0.9841\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0255 - acc: 0.9960 - precision: 0.9986 - recall: 0.9865 - val_loss: 0.0184 - val_acc: 0.9973 - val_precision: 1.0000 - val_recall: 0.9906\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0203 - acc: 0.9967 - precision: 0.9983 - recall: 0.9888 - val_loss: 0.0160 - val_acc: 0.9975 - val_precision: 0.9997 - val_recall: 0.9903\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0174 - acc: 0.9971 - precision: 0.9984 - recall: 0.9899 - val_loss: 0.0126 - val_acc: 0.9981 - val_precision: 1.0000 - val_recall: 0.9927\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0204 - acc: 0.9961 - precision: 0.9977 - recall: 0.9872 - val_loss: 0.0129 - val_acc: 0.9981 - val_precision: 0.9984 - val_recall: 0.9943\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0140 - acc: 0.9975 - precision: 0.9988 - recall: 0.9915 - val_loss: 0.0102 - val_acc: 0.9984 - val_precision: 1.0000 - val_recall: 0.9949\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0109 - acc: 0.9982 - precision: 0.9995 - recall: 0.9937 - val_loss: 0.0095 - val_acc: 0.9985 - val_precision: 1.0000 - val_recall: 0.9951\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0173 - acc: 0.9966 - precision: 0.9963 - recall: 0.9895 - val_loss: 0.0138 - val_acc: 0.9973 - val_precision: 1.0000 - val_recall: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/80\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0116 - acc: 0.9979 - precision: 0.9984 - recall: 0.9934 - val_loss: 0.0101 - val_acc: 0.9981 - val_precision: 1.0000 - val_recall: 0.9930\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0094 - acc: 0.9985 - precision: 0.9994 - recall: 0.9952 - val_loss: 0.0071 - val_acc: 0.9990 - val_precision: 0.9987 - val_recall: 0.9973\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0102 - acc: 0.9980 - precision: 0.9977 - recall: 0.9943 - val_loss: 0.0092 - val_acc: 0.9979 - val_precision: 0.9928 - val_recall: 0.9973\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0140 - acc: 0.9972 - precision: 0.9978 - recall: 0.9912 - val_loss: 0.0176 - val_acc: 0.9952 - val_precision: 0.9832 - val_recall: 0.9938\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0151 - acc: 0.9966 - precision: 0.9959 - recall: 0.9900 - val_loss: 0.0067 - val_acc: 0.9991 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.0074 - acc: 0.9987 - precision: 0.9993 - recall: 0.9959 - val_loss: 0.0051 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9978\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0059 - acc: 0.9989 - precision: 0.9992 - recall: 0.9966 - val_loss: 0.0056 - val_acc: 0.9991 - val_precision: 1.0000 - val_recall: 0.9970\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0064 - acc: 0.9988 - precision: 0.9988 - recall: 0.9970 - val_loss: 0.0070 - val_acc: 0.9985 - val_precision: 1.0000 - val_recall: 0.9949\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0110 - acc: 0.9979 - precision: 0.9985 - recall: 0.9936 - val_loss: 0.0059 - val_acc: 0.9987 - val_precision: 1.0000 - val_recall: 0.9951\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0051 - acc: 0.9992 - precision: 0.9998 - recall: 0.9974 - val_loss: 0.0039 - val_acc: 0.9994 - val_precision: 1.0000 - val_recall: 0.9981\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0084 - acc: 0.9983 - precision: 0.9982 - recall: 0.9948 - val_loss: 0.0040 - val_acc: 0.9994 - val_precision: 0.9997 - val_recall: 0.9984\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0041 - acc: 0.9994 - precision: 0.9997 - recall: 0.9979 - val_loss: 0.0072 - val_acc: 0.9985 - val_precision: 1.0000 - val_recall: 0.9946\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0080 - acc: 0.9985 - precision: 0.9988 - recall: 0.9953 - val_loss: 0.0036 - val_acc: 0.9996 - val_precision: 0.9989 - val_recall: 0.9989\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0034 - acc: 0.9995 - precision: 1.0000 - recall: 0.9983 - val_loss: 0.0073 - val_acc: 0.9975 - val_precision: 0.9896 - val_recall: 0.9989\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0140 - acc: 0.9971 - precision: 0.9974 - recall: 0.9914 - val_loss: 0.0041 - val_acc: 0.9997 - val_precision: 0.9997 - val_recall: 0.9989\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0052 - acc: 0.9989 - precision: 0.9983 - recall: 0.9971 - val_loss: 0.0179 - val_acc: 0.9959 - val_precision: 1.0000 - val_recall: 0.9844\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0076 - acc: 0.9983 - precision: 0.9991 - recall: 0.9948 - val_loss: 0.0027 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0071 - acc: 0.9984 - precision: 0.9981 - recall: 0.9957 - val_loss: 0.0030 - val_acc: 0.9996 - val_precision: 1.0000 - val_recall: 0.9984\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0031 - acc: 0.9995 - precision: 0.9999 - recall: 0.9981 - val_loss: 0.0023 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0032 - acc: 0.9995 - precision: 0.9998 - recall: 0.9980 - val_loss: 0.0022 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0032 - acc: 0.9993 - precision: 0.9992 - recall: 0.9980 - val_loss: 0.0021 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9989\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9996 - precision: 1.0000 - recall: 0.9983 - val_loss: 0.0020 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9989\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0024 - acc: 0.9995 - precision: 0.9998 - recall: 0.9984 - val_loss: 0.0019 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9992\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0018 - acc: 0.9997 - precision: 1.0000 - recall: 0.9989 - val_loss: 0.0016 - val_acc: 0.9997 - val_precision: 1.0000 - val_recall: 0.9992\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0016 - acc: 0.9997 - precision: 1.0000 - recall: 0.9990 - val_loss: 0.0014 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9997 - precision: 1.0000 - recall: 0.9991 - val_loss: 0.0013 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9997 - precision: 1.0000 - recall: 0.9991 - val_loss: 0.0012 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9998 - precision: 1.0000 - recall: 0.9992 - val_loss: 0.0011 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0013 - acc: 0.9998 - precision: 1.0000 - recall: 0.9992 - val_loss: 0.0011 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9995\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0012 - acc: 0.9998 - precision: 1.0000 - recall: 0.9992 - val_loss: 0.0010 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0011 - acc: 0.9998 - precision: 1.0000 - recall: 0.9994 - val_loss: 9.6040e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0011 - acc: 0.9998 - precision: 1.0000 - recall: 0.9997 - val_loss: 9.0990e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0010 - acc: 0.9998 - precision: 1.0000 - recall: 0.9997 - val_loss: 8.5647e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 9.7390e-04 - acc: 0.9998 - precision: 1.0000 - recall: 0.9998 - val_loss: 8.6201e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.1990e-04 - acc: 0.9998 - precision: 1.0000 - recall: 0.9998 - val_loss: 7.9960e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 8.6808e-04 - acc: 0.9998 - precision: 1.0000 - recall: 0.9998 - val_loss: 7.7319e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 8.1864e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 7.1052e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 7.7356e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 6.7013e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 16ms/step - loss: 7.3475e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 9.0130e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 6.9717e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 6.9414e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 6.5549e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 6.1635e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 6.2150e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 5.6116e-04 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Found good model!!\n",
      "################################\n",
      "1 (0,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 5s 30ms/step - loss: 0.5753 - acc: 0.7480 - precision: 0.2514 - recall: 0.1473 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5596 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5618 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5595 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5594 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5592 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.5593 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5590 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.5590 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5590 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5589 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5590 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5590 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5589 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5591 - acc: 0.7527 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "################################\n",
      "1 (1,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 5s 27ms/step - loss: 0.5512 - acc: 0.7591 - precision: 0.3463 - recall: 0.1028 - val_loss: 0.4580 - val_acc: 0.8343 - val_precision: 0.9707 - val_recall: 0.3546\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3924 - acc: 0.8541 - precision: 0.8077 - recall: 0.5381 - val_loss: 0.3240 - val_acc: 0.8935 - val_precision: 0.9443 - val_recall: 0.6221\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2564 - acc: 0.9220 - precision: 0.9623 - recall: 0.7198 - val_loss: 0.2378 - val_acc: 0.9281 - val_precision: 1.0000 - val_recall: 0.7191\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2053 - acc: 0.9407 - precision: 0.9725 - recall: 0.7893 - val_loss: 0.1579 - val_acc: 0.9561 - val_precision: 1.0000 - val_recall: 0.8329\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1250 - acc: 0.9702 - precision: 0.9887 - recall: 0.8914 - val_loss: 0.1079 - val_acc: 0.9751 - val_precision: 0.9965 - val_recall: 0.9039\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1022 - acc: 0.9760 - precision: 0.9907 - recall: 0.9137 - val_loss: 0.0966 - val_acc: 0.9775 - val_precision: 1.0000 - val_recall: 0.9127\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1881 - acc: 0.9504 - precision: 0.9691 - recall: 0.8320 - val_loss: 0.1117 - val_acc: 0.9746 - val_precision: 1.0000 - val_recall: 0.9012\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0890 - acc: 0.9802 - precision: 0.9937 - recall: 0.9266 - val_loss: 0.0946 - val_acc: 0.9773 - val_precision: 0.9971 - val_recall: 0.9124\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0746 - acc: 0.9836 - precision: 0.9958 - recall: 0.9375 - val_loss: 0.0935 - val_acc: 0.9773 - val_precision: 0.9959 - val_recall: 0.9124\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0627 - acc: 0.9867 - precision: 0.9952 - recall: 0.9516 - val_loss: 0.0445 - val_acc: 0.9903 - val_precision: 1.0000 - val_recall: 0.9622\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1185 - acc: 0.9721 - precision: 0.9779 - recall: 0.9095 - val_loss: 0.2245 - val_acc: 0.9433 - val_precision: 0.9387 - val_recall: 0.8200\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1336 - acc: 0.9666 - precision: 0.9946 - recall: 0.8742 - val_loss: 0.0792 - val_acc: 0.9825 - val_precision: 0.9960 - val_recall: 0.9357\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0704 - acc: 0.9849 - precision: 0.9898 - recall: 0.9493 - val_loss: 0.0647 - val_acc: 0.9847 - val_precision: 1.0000 - val_recall: 0.9430\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1037 - acc: 0.9775 - precision: 0.9573 - recall: 0.9476 - val_loss: 0.0452 - val_acc: 0.9921 - val_precision: 1.0000 - val_recall: 0.9700\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0344 - acc: 0.9943 - precision: 1.0000 - recall: 0.9787 - val_loss: 0.0288 - val_acc: 0.9946 - val_precision: 1.0000 - val_recall: 0.9791\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0371 - acc: 0.9935 - precision: 0.9897 - recall: 0.9842 - val_loss: 0.0463 - val_acc: 0.9914 - val_precision: 0.9788 - val_recall: 0.9877\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0367 - acc: 0.9934 - precision: 0.9897 - recall: 0.9846 - val_loss: 0.0407 - val_acc: 0.9925 - val_precision: 1.0000 - val_recall: 0.9708\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0249 - acc: 0.9955 - precision: 0.9995 - recall: 0.9826 - val_loss: 0.0184 - val_acc: 0.9960 - val_precision: 1.0000 - val_recall: 0.9850\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0172 - acc: 0.9967 - precision: 0.9994 - recall: 0.9875 - val_loss: 0.0151 - val_acc: 0.9969 - val_precision: 0.9997 - val_recall: 0.9888\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0150 - acc: 0.9970 - precision: 0.9988 - recall: 0.9887 - val_loss: 0.0124 - val_acc: 0.9975 - val_precision: 0.9997 - val_recall: 0.9920\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0121 - acc: 0.9975 - precision: 0.9991 - recall: 0.9915 - val_loss: 0.0138 - val_acc: 0.9975 - val_precision: 0.9925 - val_recall: 0.9941\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0107 - acc: 0.9979 - precision: 0.9983 - recall: 0.9927 - val_loss: 0.0092 - val_acc: 0.9982 - val_precision: 0.9997 - val_recall: 0.9938\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0088 - acc: 0.9983 - precision: 0.9992 - recall: 0.9940 - val_loss: 0.0088 - val_acc: 0.9985 - val_precision: 0.9995 - val_recall: 0.9952\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0082 - acc: 0.9984 - precision: 0.9993 - recall: 0.9948 - val_loss: 0.0088 - val_acc: 0.9985 - val_precision: 0.9987 - val_recall: 0.9952\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0087 - acc: 0.9984 - precision: 0.9984 - recall: 0.9951 - val_loss: 0.0084 - val_acc: 0.9985 - val_precision: 1.0000 - val_recall: 0.9944\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0097 - acc: 0.9983 - precision: 0.9980 - recall: 0.9949 - val_loss: 0.0079 - val_acc: 0.9986 - val_precision: 0.9976 - val_recall: 0.9960\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0080 - acc: 0.9985 - precision: 0.9988 - recall: 0.9950 - val_loss: 0.0084 - val_acc: 0.9986 - val_precision: 0.9989 - val_recall: 0.9954\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0116 - acc: 0.9980 - precision: 0.9975 - recall: 0.9943 - val_loss: 0.0102 - val_acc: 0.9979 - val_precision: 1.0000 - val_recall: 0.9917\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0099 - acc: 0.9979 - precision: 0.9961 - recall: 0.9951 - val_loss: 0.0065 - val_acc: 0.9987 - val_precision: 0.9995 - val_recall: 0.9954\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0056 - acc: 0.9990 - precision: 0.9992 - recall: 0.9969 - val_loss: 0.0060 - val_acc: 0.9987 - val_precision: 0.9997 - val_recall: 0.9954\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0053 - acc: 0.9989 - precision: 0.9986 - recall: 0.9965 - val_loss: 0.0065 - val_acc: 0.9988 - val_precision: 1.0000 - val_recall: 0.9954\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0137 - acc: 0.9974 - precision: 0.9962 - recall: 0.9926 - val_loss: 0.0788 - val_acc: 0.9865 - val_precision: 1.0000 - val_recall: 0.9462\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0342 - acc: 0.9933 - precision: 0.9991 - recall: 0.9742 - val_loss: 0.0168 - val_acc: 0.9959 - val_precision: 1.0000 - val_recall: 0.9853\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0133 - acc: 0.9966 - precision: 0.9971 - recall: 0.9896 - val_loss: 0.0101 - val_acc: 0.9980 - val_precision: 0.9970 - val_recall: 0.9941\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0095 - acc: 0.9975 - precision: 0.9973 - recall: 0.9927 - val_loss: 0.0086 - val_acc: 0.9981 - val_precision: 0.9997 - val_recall: 0.9930\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0075 - acc: 0.9984 - precision: 0.9993 - recall: 0.9946 - val_loss: 0.0075 - val_acc: 0.9984 - val_precision: 0.9997 - val_recall: 0.9944\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0069 - acc: 0.9985 - precision: 0.9985 - recall: 0.9953 - val_loss: 0.0071 - val_acc: 0.9984 - val_precision: 0.9987 - val_recall: 0.9949\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0066 - acc: 0.9984 - precision: 0.9980 - recall: 0.9957 - val_loss: 0.0054 - val_acc: 0.9986 - val_precision: 0.9981 - val_recall: 0.9963\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0046 - acc: 0.9990 - precision: 0.9984 - recall: 0.9975 - val_loss: 0.0056 - val_acc: 0.9987 - val_precision: 1.0000 - val_recall: 0.9954\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0045 - acc: 0.9991 - precision: 0.9988 - recall: 0.9972 - val_loss: 0.0052 - val_acc: 0.9987 - val_precision: 0.9984 - val_recall: 0.9957\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0038 - acc: 0.9992 - precision: 0.9985 - recall: 0.9979 - val_loss: 0.0043 - val_acc: 0.9989 - val_precision: 0.9995 - val_recall: 0.9968\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0036 - acc: 0.9993 - precision: 0.9988 - recall: 0.9979 - val_loss: 0.0045 - val_acc: 0.9991 - val_precision: 0.9995 - val_recall: 0.9968\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0040 - acc: 0.9991 - precision: 0.9987 - recall: 0.9975 - val_loss: 0.0060 - val_acc: 0.9989 - val_precision: 1.0000 - val_recall: 0.9957\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0033 - acc: 0.9994 - precision: 0.9994 - recall: 0.9978 - val_loss: 0.0036 - val_acc: 0.9990 - val_precision: 0.9987 - val_recall: 0.9973\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0028 - acc: 0.9994 - precision: 0.9988 - recall: 0.9984 - val_loss: 0.0040 - val_acc: 0.9990 - val_precision: 0.9997 - val_recall: 0.9963\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0029 - acc: 0.9993 - precision: 0.9992 - recall: 0.9980 - val_loss: 0.0034 - val_acc: 0.9991 - val_precision: 0.9973 - val_recall: 0.9984\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0038 - acc: 0.9991 - precision: 0.9984 - recall: 0.9980 - val_loss: 0.0038 - val_acc: 0.9991 - val_precision: 0.9997 - val_recall: 0.9965\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0025 - acc: 0.9993 - precision: 0.9994 - recall: 0.9982 - val_loss: 0.0031 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9971\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9996 - precision: 0.9995 - recall: 0.9991 - val_loss: 0.0029 - val_acc: 0.9992 - val_precision: 1.0000 - val_recall: 0.9971\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0018 - acc: 0.9996 - precision: 0.9995 - recall: 0.9990 - val_loss: 0.0028 - val_acc: 0.9993 - val_precision: 0.9997 - val_recall: 0.9973\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 0.9993 - precision: 0.9988 - recall: 0.9987 - val_loss: 0.0032 - val_acc: 0.9992 - val_precision: 0.9973 - val_recall: 0.9987\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9995 - precision: 0.9994 - recall: 0.9984 - val_loss: 0.0026 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9996 - precision: 0.9998 - recall: 0.9991 - val_loss: 0.0026 - val_acc: 0.9993 - val_precision: 0.9997 - val_recall: 0.9973\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9995 - precision: 0.9994 - recall: 0.9992 - val_loss: 0.0030 - val_acc: 0.9991 - val_precision: 1.0000 - val_recall: 0.9971\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9998 - recall: 0.9993 - val_loss: 0.0018 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9984\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0016 - acc: 0.9997 - precision: 0.9998 - recall: 0.9992 - val_loss: 0.0038 - val_acc: 0.9989 - val_precision: 0.9955 - val_recall: 0.9992\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0020 - acc: 0.9995 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0068 - val_acc: 0.9985 - val_precision: 0.9941 - val_recall: 0.9992\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9998 - recall: 0.9993 - val_loss: 0.0016 - val_acc: 0.9996 - val_precision: 1.0000 - val_recall: 0.9984\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0013 - acc: 0.9997 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.0016 - val_acc: 0.9996 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 0.9998 - precision: 0.9999 - recall: 0.9993 - val_loss: 0.0016 - val_acc: 0.9996 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 0.9998 - precision: 0.9999 - recall: 0.9995 - val_loss: 0.0062 - val_acc: 0.9985 - val_precision: 1.0000 - val_recall: 0.9944\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0022 - acc: 0.9994 - precision: 0.9991 - recall: 0.9986 - val_loss: 0.0021 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9981\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 0.9998 - precision: 0.9998 - recall: 0.9992 - val_loss: 0.0039 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9997 - precision: 0.9995 - recall: 0.9991 - val_loss: 0.0027 - val_acc: 0.9992 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0240 - acc: 0.9957 - precision: 0.9933 - recall: 0.9879 - val_loss: 0.0073 - val_acc: 0.9986 - val_precision: 0.9957 - val_recall: 0.9965\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0089 - acc: 0.9985 - precision: 0.9979 - recall: 0.9960 - val_loss: 0.0105 - val_acc: 0.9981 - val_precision: 0.9918 - val_recall: 0.9984\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0042 - acc: 0.9991 - precision: 0.9985 - recall: 0.9980 - val_loss: 0.0038 - val_acc: 0.9990 - val_precision: 1.0000 - val_recall: 0.9965\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0022 - acc: 0.9996 - precision: 0.9992 - recall: 0.9985 - val_loss: 0.0032 - val_acc: 0.9991 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0026 - acc: 0.9994 - precision: 0.9988 - recall: 0.9986 - val_loss: 0.0033 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0019 - acc: 0.9994 - precision: 0.9992 - recall: 0.9985 - val_loss: 0.0029 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0012 - acc: 0.9997 - precision: 0.9998 - recall: 0.9993 - val_loss: 0.0029 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9981\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9998 - recall: 0.9991 - val_loss: 0.0019 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0022 - acc: 0.9995 - precision: 0.9990 - recall: 0.9988 - val_loss: 0.0016 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9989\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0045 - acc: 0.9993 - precision: 0.9992 - recall: 0.9978 - val_loss: 0.0085 - val_acc: 0.9982 - val_precision: 0.9987 - val_recall: 0.9949\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0043 - acc: 0.9990 - precision: 0.9988 - recall: 0.9966 - val_loss: 0.0026 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9979\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0013 - acc: 0.9997 - precision: 0.9999 - recall: 0.9993 - val_loss: 0.0038 - val_acc: 0.9992 - val_precision: 1.0000 - val_recall: 0.9971\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0018 - acc: 0.9996 - precision: 0.9993 - recall: 0.9991 - val_loss: 0.0026 - val_acc: 0.9991 - val_precision: 0.9960 - val_recall: 0.9992\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0017 - acc: 0.9997 - precision: 0.9997 - recall: 0.9991 - val_loss: 0.0018 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9984\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9996 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0030 - val_acc: 0.9994 - val_precision: 1.0000 - val_recall: 0.9979\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0018 - acc: 0.9997 - precision: 0.9995 - recall: 0.9992 - val_loss: 0.0034 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Found good model!!\n",
      "################################\n",
      "2 (0,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 26ms/step - loss: 0.5779 - acc: 0.7430 - precision: 0.2507 - recall: 0.1238 - val_loss: 0.5628 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5630 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5628 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "################################\n",
      "2 (1,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 27ms/step - loss: 0.5830 - acc: 0.7323 - precision: 0.2446 - recall: 0.1507 - val_loss: 0.5628 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5639 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5639 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "################################\n",
      "2 (2,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 26ms/step - loss: 0.5824 - acc: 0.7363 - precision: 0.2568 - recall: 0.1702 - val_loss: 0.5620 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5802 - acc: 0.7181 - precision: 0.2844 - recall: 0.1257 - val_loss: 0.5651 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5623 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5636 - acc: 0.7490 - precision: 1.0000 - recall: 1.1382e-04 - val_loss: 0.5623 - val_acc: 0.7499 - val_precision: 1.0000 - val_recall: 0.0011\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 1.0000 - recall: 6.8290e-04 - val_loss: 0.5623 - val_acc: 0.7499 - val_precision: 1.0000 - val_recall: 0.0011\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 1.0000 - recall: 7.9672e-04 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 1.0000 - val_recall: 0.0011\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.6207 - recall: 0.0020 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.4348 - val_recall: 0.0027\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7488 - precision: 0.4000 - recall: 0.0023 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.5000 - val_recall: 0.0011\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.7333 - recall: 0.0013 - val_loss: 0.5622 - val_acc: 0.7502 - val_precision: 1.0000 - val_recall: 0.0011\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7491 - precision: 1.0000 - recall: 5.6909e-04 - val_loss: 0.5623 - val_acc: 0.7501 - val_precision: 1.0000 - val_recall: 7.9979e-04\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7491 - precision: 1.0000 - recall: 3.4145e-04 - val_loss: 0.5622 - val_acc: 0.7501 - val_precision: 1.0000 - val_recall: 7.9979e-04\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7491 - precision: 1.0000 - recall: 3.4145e-04 - val_loss: 0.5623 - val_acc: 0.7501 - val_precision: 1.0000 - val_recall: 7.9979e-04\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7488 - precision: 0.3684 - recall: 7.9672e-04 - val_loss: 0.5629 - val_acc: 0.7483 - val_precision: 0.3143 - val_recall: 0.0059\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7486 - precision: 0.3182 - recall: 0.0032 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5629 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5628 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5622 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5632 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5621 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5627 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5599 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5609 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5638 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5634 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5622 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5568 - acc: 0.7494 - precision: 0.5152 - recall: 0.0542 - val_loss: 0.5409 - val_acc: 0.7681 - val_precision: 0.9587 - val_recall: 0.1176\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5606 - acc: 0.7513 - precision: 0.4917 - recall: 0.0437 - val_loss: 0.5622 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5624 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5569 - acc: 0.7490 - precision: 0.5837 - recall: 0.0139 - val_loss: 0.5302 - val_acc: 0.7499 - val_precision: 1.0000 - val_recall: 0.1490\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5383 - acc: 0.7676 - precision: 0.7012 - recall: 0.1573 - val_loss: 0.4979 - val_acc: 0.8039 - val_precision: 0.9869 - val_recall: 0.2207\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4816 - acc: 0.8094 - precision: 0.8421 - recall: 0.2926 - val_loss: 0.5451 - val_acc: 0.7773 - val_precision: 0.9724 - val_recall: 0.1125\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5664 - acc: 0.7494 - precision: 1.0000 - recall: 0.0018 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5629 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5604 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5563 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5506 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5509 - acc: 0.7498 - precision: 1.0000 - recall: 0.0044 - val_loss: 0.5002 - val_acc: 0.7832 - val_precision: 1.0000 - val_recall: 0.1522\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5581 - acc: 0.7552 - precision: 0.6132 - recall: 0.0626 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5632 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5622 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5624 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5609 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5504 - acc: 0.7490 - precision: 0.7485 - recall: 0.0566 - val_loss: 0.5196 - val_acc: 0.7499 - val_precision: 0.5682 - val_recall: 0.4130\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5346 - acc: 0.7559 - precision: 0.5566 - recall: 0.2276 - val_loss: 0.4453 - val_acc: 0.8157 - val_precision: 0.7435 - val_recall: 0.5596\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5320 - acc: 0.7763 - precision: 0.6691 - recall: 0.1975 - val_loss: 0.5589 - val_acc: 0.7499 - val_precision: 0.3333 - val_recall: 5.3319e-04\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5023 - acc: 0.7975 - precision: 0.8474 - recall: 0.2370 - val_loss: 0.4200 - val_acc: 0.8579 - val_precision: 0.8529 - val_recall: 0.5039\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4168 - acc: 0.8508 - precision: 0.9050 - recall: 0.4513 - val_loss: 0.4164 - val_acc: 0.8479 - val_precision: 0.9739 - val_recall: 0.4074\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3888 - acc: 0.8623 - precision: 0.9244 - recall: 0.4882 - val_loss: 0.3661 - val_acc: 0.8731 - val_precision: 0.9241 - val_recall: 0.5356\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3715 - acc: 0.8681 - precision: 0.9161 - recall: 0.5198 - val_loss: 0.3431 - val_acc: 0.8798 - val_precision: 0.9737 - val_recall: 0.5420\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.2968 - acc: 0.9021 - precision: 0.9147 - recall: 0.6663 - val_loss: 0.1926 - val_acc: 0.9449 - val_precision: 0.9869 - val_recall: 0.8035\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.2232 - acc: 0.9337 - precision: 0.9369 - recall: 0.7852 - val_loss: 0.2908 - val_acc: 0.9001 - val_precision: 0.9873 - val_recall: 0.6201\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1579 - acc: 0.9545 - precision: 0.9376 - recall: 0.8722 - val_loss: 0.1218 - val_acc: 0.9678 - val_precision: 0.9367 - val_recall: 0.9195\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1149 - acc: 0.9694 - precision: 0.9624 - recall: 0.9094 - val_loss: 0.1002 - val_acc: 0.9736 - val_precision: 0.9724 - val_recall: 0.9198\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1059 - acc: 0.9711 - precision: 0.9688 - recall: 0.9138 - val_loss: 0.0907 - val_acc: 0.9755 - val_precision: 0.9725 - val_recall: 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0991 - acc: 0.9726 - precision: 0.9698 - recall: 0.9183 - val_loss: 0.0849 - val_acc: 0.9765 - val_precision: 0.9880 - val_recall: 0.9208\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0881 - acc: 0.9766 - precision: 0.9756 - recall: 0.9281 - val_loss: 0.0850 - val_acc: 0.9777 - val_precision: 0.9951 - val_recall: 0.9184\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0822 - acc: 0.9781 - precision: 0.9782 - recall: 0.9332 - val_loss: 0.0713 - val_acc: 0.9820 - val_precision: 0.9660 - val_recall: 0.9544\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0712 - acc: 0.9820 - precision: 0.9824 - recall: 0.9440 - val_loss: 0.0633 - val_acc: 0.9842 - val_precision: 0.9712 - val_recall: 0.9613\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0740 - acc: 0.9813 - precision: 0.9814 - recall: 0.9417 - val_loss: 0.0634 - val_acc: 0.9840 - val_precision: 0.9922 - val_recall: 0.9472\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0671 - acc: 0.9829 - precision: 0.9854 - recall: 0.9461 - val_loss: 0.0545 - val_acc: 0.9870 - val_precision: 0.9821 - val_recall: 0.9635\n",
      "################################\n",
      "2 (0, 1)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 27ms/step - loss: 0.5756 - acc: 0.7477 - precision: 0.2551 - recall: 0.1002 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5629 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5630 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5628 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "################################\n",
      "2 (0, 2)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 24ms/step - loss: 0.5823 - acc: 0.7419 - precision: 0.2520 - recall: 0.1642 - val_loss: 0.5614 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5536 - acc: 0.7544 - precision: 0.5877 - recall: 0.0805 - val_loss: 0.5305 - val_acc: 0.7807 - val_precision: 0.6797 - val_recall: 0.2223\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5115 - acc: 0.7883 - precision: 0.7108 - recall: 0.2512 - val_loss: 0.5194 - val_acc: 0.7867 - val_precision: 1.0000 - val_recall: 0.1565\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5111 - acc: 0.7870 - precision: 0.7647 - recall: 0.2167 - val_loss: 0.5409 - val_acc: 0.7646 - val_precision: 1.0000 - val_recall: 0.0690\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4938 - acc: 0.7963 - precision: 0.7921 - recall: 0.2546 - val_loss: 0.4581 - val_acc: 0.8177 - val_precision: 0.9855 - val_recall: 0.2906\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4825 - acc: 0.8026 - precision: 0.7795 - recall: 0.2929 - val_loss: 0.4314 - val_acc: 0.8343 - val_precision: 0.9168 - val_recall: 0.3906\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4344 - acc: 0.8336 - precision: 0.8442 - recall: 0.4053 - val_loss: 0.3913 - val_acc: 0.8593 - val_precision: 0.7660 - val_recall: 0.5689\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5106 - acc: 0.7831 - precision: 0.8089 - recall: 0.1715 - val_loss: 0.5486 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5345 - acc: 0.7637 - precision: 0.8217 - recall: 0.1317 - val_loss: 0.5018 - val_acc: 0.8027 - val_precision: 0.8130 - val_recall: 0.2642\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4968 - acc: 0.7993 - precision: 0.8101 - recall: 0.2554 - val_loss: 0.4709 - val_acc: 0.8142 - val_precision: 0.8481 - val_recall: 0.3007\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4893 - acc: 0.8026 - precision: 0.8254 - recall: 0.2604 - val_loss: 0.4585 - val_acc: 0.8179 - val_precision: 0.7383 - val_recall: 0.3708\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4732 - acc: 0.8095 - precision: 0.7818 - recall: 0.3071 - val_loss: 0.4458 - val_acc: 0.8233 - val_precision: 0.9226 - val_recall: 0.3239\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4700 - acc: 0.8110 - precision: 0.7846 - recall: 0.3378 - val_loss: 0.5630 - val_acc: 0.7616 - val_precision: 1.0000 - val_recall: 0.0504\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4903 - acc: 0.7989 - precision: 0.8360 - recall: 0.2443 - val_loss: 0.4464 - val_acc: 0.8286 - val_precision: 0.7456 - val_recall: 0.4439\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4190 - acc: 0.8369 - precision: 0.8125 - recall: 0.4439 - val_loss: 0.4625 - val_acc: 0.8173 - val_precision: 0.9713 - val_recall: 0.2890\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4079 - acc: 0.8471 - precision: 0.8425 - recall: 0.4665 - val_loss: 0.5056 - val_acc: 0.7845 - val_precision: 0.4661 - val_recall: 0.4575\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4533 - acc: 0.8177 - precision: 0.8257 - recall: 0.3386 - val_loss: 0.4195 - val_acc: 0.8367 - val_precision: 0.8797 - val_recall: 0.4018\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4235 - acc: 0.8332 - precision: 0.8325 - recall: 0.4118 - val_loss: 0.3879 - val_acc: 0.8506 - val_precision: 0.8999 - val_recall: 0.4556\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3915 - acc: 0.8515 - precision: 0.8194 - recall: 0.5059 - val_loss: 0.3752 - val_acc: 0.8551 - val_precision: 0.9872 - val_recall: 0.4529\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3095 - acc: 0.8920 - precision: 0.9011 - recall: 0.6313 - val_loss: 0.2412 - val_acc: 0.9221 - val_precision: 0.9290 - val_recall: 0.7427\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3433 - acc: 0.8761 - precision: 0.8800 - recall: 0.5725 - val_loss: 0.4270 - val_acc: 0.8391 - val_precision: 0.8159 - val_recall: 0.4348\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4324 - acc: 0.8355 - precision: 0.8943 - recall: 0.3901 - val_loss: 0.5064 - val_acc: 0.7869 - val_precision: 0.9984 - val_recall: 0.1637\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3949 - acc: 0.8509 - precision: 0.8607 - recall: 0.4832 - val_loss: 0.2429 - val_acc: 0.9252 - val_precision: 0.9491 - val_recall: 0.7457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.2540 - acc: 0.9180 - precision: 0.9249 - recall: 0.7272 - val_loss: 0.2860 - val_acc: 0.9011 - val_precision: 0.9919 - val_recall: 0.6185\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2075 - acc: 0.9338 - precision: 0.9404 - recall: 0.7873 - val_loss: 0.1805 - val_acc: 0.9438 - val_precision: 0.9290 - val_recall: 0.8339\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1948 - acc: 0.9397 - precision: 0.9393 - recall: 0.8089 - val_loss: 0.1714 - val_acc: 0.9479 - val_precision: 0.9808 - val_recall: 0.8152\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1741 - acc: 0.9465 - precision: 0.9412 - recall: 0.8339 - val_loss: 0.1801 - val_acc: 0.9451 - val_precision: 0.9904 - val_recall: 0.7953\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1900 - acc: 0.9392 - precision: 0.9288 - recall: 0.8163 - val_loss: 0.1577 - val_acc: 0.9523 - val_precision: 0.9672 - val_recall: 0.8411\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1716 - acc: 0.9473 - precision: 0.9496 - recall: 0.8294 - val_loss: 0.1396 - val_acc: 0.9574 - val_precision: 0.9719 - val_recall: 0.8590\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1427 - acc: 0.9567 - precision: 0.9502 - recall: 0.8700 - val_loss: 0.1429 - val_acc: 0.9567 - val_precision: 0.9891 - val_recall: 0.8456\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1406 - acc: 0.9568 - precision: 0.9486 - recall: 0.8710 - val_loss: 0.1227 - val_acc: 0.9625 - val_precision: 0.9734 - val_recall: 0.8782\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1189 - acc: 0.9647 - precision: 0.9631 - recall: 0.8931 - val_loss: 0.1070 - val_acc: 0.9691 - val_precision: 0.9862 - val_recall: 0.8928\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1063 - acc: 0.9690 - precision: 0.9629 - recall: 0.9078 - val_loss: 0.1135 - val_acc: 0.9655 - val_precision: 0.9642 - val_recall: 0.8976\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1002 - acc: 0.9710 - precision: 0.9680 - recall: 0.9155 - val_loss: 0.0891 - val_acc: 0.9755 - val_precision: 0.9726 - val_recall: 0.9283\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0874 - acc: 0.9754 - precision: 0.9699 - recall: 0.9285 - val_loss: 0.0855 - val_acc: 0.9743 - val_precision: 0.9376 - val_recall: 0.9501\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0846 - acc: 0.9763 - precision: 0.9722 - recall: 0.9319 - val_loss: 0.0865 - val_acc: 0.9743 - val_precision: 0.9561 - val_recall: 0.9347\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0914 - acc: 0.9736 - precision: 0.9706 - recall: 0.9218 - val_loss: 0.0733 - val_acc: 0.9796 - val_precision: 0.9873 - val_recall: 0.9339\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0771 - acc: 0.9781 - precision: 0.9763 - recall: 0.9359 - val_loss: 0.0706 - val_acc: 0.9812 - val_precision: 0.9915 - val_recall: 0.9350\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0774 - acc: 0.9780 - precision: 0.9753 - recall: 0.9364 - val_loss: 0.0774 - val_acc: 0.9779 - val_precision: 0.9971 - val_recall: 0.9176\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0820 - acc: 0.9767 - precision: 0.9743 - recall: 0.9307 - val_loss: 0.1059 - val_acc: 0.9717 - val_precision: 0.9979 - val_recall: 0.8934\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0768 - acc: 0.9787 - precision: 0.9774 - recall: 0.9361 - val_loss: 0.0715 - val_acc: 0.9802 - val_precision: 0.9522 - val_recall: 0.9565\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0665 - acc: 0.9812 - precision: 0.9797 - recall: 0.9432 - val_loss: 0.0585 - val_acc: 0.9845 - val_precision: 0.9859 - val_recall: 0.9512\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0609 - acc: 0.9832 - precision: 0.9836 - recall: 0.9486 - val_loss: 0.0575 - val_acc: 0.9847 - val_precision: 0.9963 - val_recall: 0.9448\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0580 - acc: 0.9845 - precision: 0.9854 - recall: 0.9514 - val_loss: 0.0619 - val_acc: 0.9825 - val_precision: 0.9606 - val_recall: 0.9632\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0827 - acc: 0.9755 - precision: 0.9699 - recall: 0.9267 - val_loss: 0.0927 - val_acc: 0.9721 - val_precision: 0.9095 - val_recall: 0.9619\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0629 - acc: 0.9820 - precision: 0.9817 - recall: 0.9461 - val_loss: 0.0540 - val_acc: 0.9849 - val_precision: 0.9817 - val_recall: 0.9563\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0534 - acc: 0.9855 - precision: 0.9864 - recall: 0.9560 - val_loss: 0.0496 - val_acc: 0.9862 - val_precision: 0.9762 - val_recall: 0.9640\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0490 - acc: 0.9867 - precision: 0.9872 - recall: 0.9599 - val_loss: 0.0463 - val_acc: 0.9877 - val_precision: 0.9858 - val_recall: 0.9632\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0499 - acc: 0.9863 - precision: 0.9869 - recall: 0.9581 - val_loss: 0.0559 - val_acc: 0.9829 - val_precision: 0.9534 - val_recall: 0.9709\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0567 - acc: 0.9836 - precision: 0.9835 - recall: 0.9505 - val_loss: 0.0463 - val_acc: 0.9875 - val_precision: 0.9871 - val_recall: 0.9621\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0469 - acc: 0.9871 - precision: 0.9863 - recall: 0.9607 - val_loss: 0.0430 - val_acc: 0.9888 - val_precision: 0.9948 - val_recall: 0.9611\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0443 - acc: 0.9874 - precision: 0.9866 - recall: 0.9624 - val_loss: 0.0520 - val_acc: 0.9845 - val_precision: 0.9629 - val_recall: 0.9699\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0421 - acc: 0.9884 - precision: 0.9867 - recall: 0.9651 - val_loss: 0.0403 - val_acc: 0.9881 - val_precision: 0.9716 - val_recall: 0.9752\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0447 - acc: 0.9876 - precision: 0.9860 - recall: 0.9636 - val_loss: 0.0373 - val_acc: 0.9901 - val_precision: 0.9894 - val_recall: 0.9675\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0478 - acc: 0.9869 - precision: 0.9855 - recall: 0.9603 - val_loss: 0.0412 - val_acc: 0.9884 - val_precision: 0.9840 - val_recall: 0.9651\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0476 - acc: 0.9864 - precision: 0.9857 - recall: 0.9603 - val_loss: 0.0434 - val_acc: 0.9889 - val_precision: 0.9901 - val_recall: 0.9640\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0400 - acc: 0.9891 - precision: 0.9880 - recall: 0.9679 - val_loss: 0.0427 - val_acc: 0.9874 - val_precision: 0.9956 - val_recall: 0.9557\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0366 - acc: 0.9896 - precision: 0.9888 - recall: 0.9689 - val_loss: 0.0362 - val_acc: 0.9902 - val_precision: 0.9902 - val_recall: 0.9707\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0431 - acc: 0.9878 - precision: 0.9870 - recall: 0.9627 - val_loss: 0.0518 - val_acc: 0.9863 - val_precision: 0.9931 - val_recall: 0.9547\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0353 - acc: 0.9902 - precision: 0.9870 - recall: 0.9710 - val_loss: 0.0321 - val_acc: 0.9907 - val_precision: 0.9905 - val_recall: 0.9733\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0339 - acc: 0.9905 - precision: 0.9900 - recall: 0.9714 - val_loss: 0.0386 - val_acc: 0.9879 - val_precision: 0.9663 - val_recall: 0.9795\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0312 - acc: 0.9912 - precision: 0.9891 - recall: 0.9731 - val_loss: 0.0357 - val_acc: 0.9903 - val_precision: 0.9907 - val_recall: 0.9685\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0299 - acc: 0.9915 - precision: 0.9899 - recall: 0.9753 - val_loss: 0.0294 - val_acc: 0.9921 - val_precision: 0.9924 - val_recall: 0.9757\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0361 - acc: 0.9900 - precision: 0.9898 - recall: 0.9701 - val_loss: 0.0278 - val_acc: 0.9923 - val_precision: 0.9954 - val_recall: 0.9739\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0417 - acc: 0.9880 - precision: 0.9859 - recall: 0.9645 - val_loss: 0.0314 - val_acc: 0.9913 - val_precision: 0.9959 - val_recall: 0.9712\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0309 - acc: 0.9909 - precision: 0.9883 - recall: 0.9747 - val_loss: 0.0274 - val_acc: 0.9925 - val_precision: 0.9874 - val_recall: 0.9795\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0258 - acc: 0.9928 - precision: 0.9920 - recall: 0.9787 - val_loss: 0.0281 - val_acc: 0.9920 - val_precision: 0.9916 - val_recall: 0.9763\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0295 - acc: 0.9914 - precision: 0.9880 - recall: 0.9768 - val_loss: 0.0272 - val_acc: 0.9923 - val_precision: 0.9892 - val_recall: 0.9787\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0273 - acc: 0.9919 - precision: 0.9897 - recall: 0.9767 - val_loss: 0.0251 - val_acc: 0.9930 - val_precision: 0.9967 - val_recall: 0.9757\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0282 - acc: 0.9921 - precision: 0.9908 - recall: 0.9762 - val_loss: 0.0240 - val_acc: 0.9933 - val_precision: 0.9932 - val_recall: 0.9792\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0223 - acc: 0.9940 - precision: 0.9930 - recall: 0.9824 - val_loss: 0.0212 - val_acc: 0.9939 - val_precision: 0.9959 - val_recall: 0.9805\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0246 - acc: 0.9931 - precision: 0.9909 - recall: 0.9805 - val_loss: 0.0214 - val_acc: 0.9939 - val_precision: 0.9917 - val_recall: 0.9821\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0245 - acc: 0.9929 - precision: 0.9907 - recall: 0.9796 - val_loss: 0.0247 - val_acc: 0.9927 - val_precision: 0.9911 - val_recall: 0.9792\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0256 - acc: 0.9929 - precision: 0.9917 - recall: 0.9784 - val_loss: 0.0247 - val_acc: 0.9932 - val_precision: 0.9962 - val_recall: 0.9773\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0539 - acc: 0.9843 - precision: 0.9787 - recall: 0.9575 - val_loss: 0.0291 - val_acc: 0.9917 - val_precision: 0.9905 - val_recall: 0.9749\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0248 - acc: 0.9927 - precision: 0.9911 - recall: 0.9786 - val_loss: 0.0260 - val_acc: 0.9923 - val_precision: 0.9930 - val_recall: 0.9771\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0210 - acc: 0.9941 - precision: 0.9929 - recall: 0.9827 - val_loss: 0.0220 - val_acc: 0.9939 - val_precision: 0.9909 - val_recall: 0.9837\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0203 - acc: 0.9937 - precision: 0.9920 - recall: 0.9830 - val_loss: 0.0240 - val_acc: 0.9929 - val_precision: 0.9965 - val_recall: 0.9768\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0176 - acc: 0.9949 - precision: 0.9941 - recall: 0.9854 - val_loss: 0.0214 - val_acc: 0.9939 - val_precision: 0.9992 - val_recall: 0.9781\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0178 - acc: 0.9949 - precision: 0.9937 - recall: 0.9852 - val_loss: 0.0220 - val_acc: 0.9935 - val_precision: 0.9989 - val_recall: 0.9773\n",
      "################################\n",
      "2 (1, 2)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 26ms/step - loss: 0.5730 - acc: 0.7434 - precision: 0.2644 - recall: 0.0827 - val_loss: 0.5619 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5518 - acc: 0.7565 - precision: 0.7449 - recall: 0.0495 - val_loss: 0.5034 - val_acc: 0.7999 - val_precision: 0.9899 - val_recall: 0.2082\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5490 - acc: 0.7599 - precision: 0.7461 - recall: 0.0645 - val_loss: 0.5576 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5446 - acc: 0.7570 - precision: 0.7777 - recall: 0.0928 - val_loss: 0.5241 - val_acc: 0.7880 - val_precision: 0.9306 - val_recall: 0.1717\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5340 - acc: 0.7749 - precision: 0.7238 - recall: 0.1658 - val_loss: 0.5188 - val_acc: 0.7893 - val_precision: 0.9771 - val_recall: 0.1704\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5134 - acc: 0.7918 - precision: 0.8692 - recall: 0.2012 - val_loss: 0.4935 - val_acc: 0.8061 - val_precision: 0.7402 - val_recall: 0.2978\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5362 - acc: 0.7707 - precision: 0.8102 - recall: 0.1088 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5634 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5637 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5635 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5632 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5636 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5626 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5625 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5620 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5658 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5611 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5641 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5633 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5613 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5568 - acc: 0.7490 - precision: 0.5753 - recall: 0.0217 - val_loss: 0.5313 - val_acc: 0.7499 - val_precision: 0.6261 - val_recall: 0.2330\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5456 - acc: 0.7614 - precision: 0.6696 - recall: 0.1040 - val_loss: 0.5545 - val_acc: 0.7513 - val_precision: 1.0000 - val_recall: 0.0067\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5473 - acc: 0.7564 - precision: 0.5505 - recall: 0.1445 - val_loss: 0.5624 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5621 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5589 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5516 - acc: 0.7490 - precision: 0.9710 - recall: 0.0076 - val_loss: 0.5329 - val_acc: 0.7499 - val_precision: 0.9976 - val_recall: 0.1128\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5080 - acc: 0.7849 - precision: 0.8160 - recall: 0.2721 - val_loss: 0.5725 - val_acc: 0.7501 - val_precision: 1.0000 - val_recall: 0.0019\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5634 - acc: 0.7490 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.7499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5479 - acc: 0.7591 - precision: 0.6482 - recall: 0.0881 - val_loss: 0.4936 - val_acc: 0.8099 - val_precision: 0.9410 - val_recall: 0.2722\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4748 - acc: 0.8190 - precision: 0.8420 - recall: 0.3384 - val_loss: 0.4405 - val_acc: 0.8417 - val_precision: 0.7968 - val_recall: 0.4577\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4480 - acc: 0.8331 - precision: 0.8567 - recall: 0.4036 - val_loss: 0.4265 - val_acc: 0.8451 - val_precision: 0.9217 - val_recall: 0.4239\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4212 - acc: 0.8466 - precision: 0.8871 - recall: 0.4479 - val_loss: 0.4072 - val_acc: 0.8535 - val_precision: 0.9754 - val_recall: 0.4335\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4312 - acc: 0.8385 - precision: 0.8754 - recall: 0.4102 - val_loss: 0.3878 - val_acc: 0.8610 - val_precision: 0.9491 - val_recall: 0.4775\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4121 - acc: 0.8471 - precision: 0.8806 - recall: 0.4467 - val_loss: 0.3861 - val_acc: 0.8646 - val_precision: 0.7483 - val_recall: 0.6356\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3896 - acc: 0.8583 - precision: 0.8740 - recall: 0.5083 - val_loss: 0.3802 - val_acc: 0.8659 - val_precision: 0.8418 - val_recall: 0.5489\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3786 - acc: 0.8644 - precision: 0.8802 - recall: 0.5299 - val_loss: 0.2902 - val_acc: 0.9082 - val_precision: 0.9852 - val_recall: 0.6545\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3032 - acc: 0.8997 - precision: 0.9066 - recall: 0.6638 - val_loss: 0.2469 - val_acc: 0.9230 - val_precision: 0.9806 - val_recall: 0.7161\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2399 - acc: 0.9257 - precision: 0.9307 - recall: 0.7601 - val_loss: 0.2172 - val_acc: 0.9315 - val_precision: 0.9876 - val_recall: 0.7459\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2065 - acc: 0.9373 - precision: 0.9374 - recall: 0.8024 - val_loss: 0.1872 - val_acc: 0.9449 - val_precision: 0.9820 - val_recall: 0.8003\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1675 - acc: 0.9505 - precision: 0.9456 - recall: 0.8501 - val_loss: 0.1341 - val_acc: 0.9613 - val_precision: 0.9411 - val_recall: 0.8952\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1478 - acc: 0.9559 - precision: 0.9509 - recall: 0.8662 - val_loss: 0.1349 - val_acc: 0.9596 - val_precision: 0.9910 - val_recall: 0.8542\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1200 - acc: 0.9651 - precision: 0.9653 - recall: 0.8920 - val_loss: 0.0950 - val_acc: 0.9728 - val_precision: 0.9651 - val_recall: 0.9224\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1468 - acc: 0.9547 - precision: 0.9462 - recall: 0.8665 - val_loss: 0.0975 - val_acc: 0.9714 - val_precision: 0.9760 - val_recall: 0.9112\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0922 - acc: 0.9735 - precision: 0.9675 - recall: 0.9228 - val_loss: 0.1165 - val_acc: 0.9617 - val_precision: 0.8796 - val_recall: 0.9528\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0813 - acc: 0.9765 - precision: 0.9685 - recall: 0.9338 - val_loss: 0.0811 - val_acc: 0.9784 - val_precision: 0.9971 - val_recall: 0.9214\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0684 - acc: 0.9811 - precision: 0.9794 - recall: 0.9431 - val_loss: 0.0571 - val_acc: 0.9851 - val_precision: 0.9820 - val_recall: 0.9600\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0686 - acc: 0.9803 - precision: 0.9784 - recall: 0.9413 - val_loss: 0.0602 - val_acc: 0.9823 - val_precision: 0.9831 - val_recall: 0.9488\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0600 - acc: 0.9828 - precision: 0.9816 - recall: 0.9512 - val_loss: 0.0464 - val_acc: 0.9877 - val_precision: 0.9872 - val_recall: 0.9640\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0541 - acc: 0.9853 - precision: 0.9862 - recall: 0.9534 - val_loss: 0.0422 - val_acc: 0.9881 - val_precision: 0.9869 - val_recall: 0.9653\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0496 - acc: 0.9864 - precision: 0.9873 - recall: 0.9580 - val_loss: 0.0455 - val_acc: 0.9877 - val_precision: 0.9901 - val_recall: 0.9619\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0435 - acc: 0.9872 - precision: 0.9850 - recall: 0.9631 - val_loss: 0.0386 - val_acc: 0.9899 - val_precision: 0.9899 - val_recall: 0.9680\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0456 - acc: 0.9873 - precision: 0.9881 - recall: 0.9606 - val_loss: 0.0454 - val_acc: 0.9860 - val_precision: 0.9664 - val_recall: 0.9725\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0419 - acc: 0.9884 - precision: 0.9894 - recall: 0.9645 - val_loss: 0.0350 - val_acc: 0.9909 - val_precision: 0.9873 - val_recall: 0.9723\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0421 - acc: 0.9875 - precision: 0.9864 - recall: 0.9634 - val_loss: 0.0368 - val_acc: 0.9895 - val_precision: 0.9923 - val_recall: 0.9669\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0373 - acc: 0.9894 - precision: 0.9897 - recall: 0.9671 - val_loss: 0.0360 - val_acc: 0.9897 - val_precision: 0.9904 - val_recall: 0.9675\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0353 - acc: 0.9897 - precision: 0.9911 - recall: 0.9669 - val_loss: 0.0378 - val_acc: 0.9893 - val_precision: 0.9810 - val_recall: 0.9752\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0349 - acc: 0.9900 - precision: 0.9901 - recall: 0.9695 - val_loss: 0.0383 - val_acc: 0.9889 - val_precision: 0.9934 - val_recall: 0.9635\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0354 - acc: 0.9896 - precision: 0.9899 - recall: 0.9687 - val_loss: 0.0302 - val_acc: 0.9919 - val_precision: 0.9913 - val_recall: 0.9747\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0303 - acc: 0.9911 - precision: 0.9903 - recall: 0.9737 - val_loss: 0.0293 - val_acc: 0.9915 - val_precision: 0.9959 - val_recall: 0.9707\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0337 - acc: 0.9897 - precision: 0.9861 - recall: 0.9718 - val_loss: 0.0387 - val_acc: 0.9891 - val_precision: 0.9838 - val_recall: 0.9704\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0302 - acc: 0.9911 - precision: 0.9895 - recall: 0.9747 - val_loss: 0.0345 - val_acc: 0.9913 - val_precision: 0.9818 - val_recall: 0.9795\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0319 - acc: 0.9911 - precision: 0.9904 - recall: 0.9727 - val_loss: 0.0514 - val_acc: 0.9831 - val_precision: 0.9307 - val_recall: 0.9915\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0297 - acc: 0.9908 - precision: 0.9888 - recall: 0.9750 - val_loss: 0.0349 - val_acc: 0.9885 - val_precision: 0.9593 - val_recall: 0.9853\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0321 - acc: 0.9906 - precision: 0.9884 - recall: 0.9737 - val_loss: 0.0256 - val_acc: 0.9927 - val_precision: 0.9856 - val_recall: 0.9824\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0274 - acc: 0.9921 - precision: 0.9906 - recall: 0.9788 - val_loss: 0.0270 - val_acc: 0.9931 - val_precision: 0.9935 - val_recall: 0.9787\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0295 - acc: 0.9913 - precision: 0.9900 - recall: 0.9758 - val_loss: 0.0247 - val_acc: 0.9932 - val_precision: 0.9845 - val_recall: 0.9835\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0269 - acc: 0.9923 - precision: 0.9888 - recall: 0.9789 - val_loss: 0.0243 - val_acc: 0.9933 - val_precision: 0.9984 - val_recall: 0.9768\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0247 - acc: 0.9931 - precision: 0.9911 - recall: 0.9804 - val_loss: 0.0225 - val_acc: 0.9939 - val_precision: 0.9917 - val_recall: 0.9832\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0212 - acc: 0.9936 - precision: 0.9924 - recall: 0.9832 - val_loss: 0.0227 - val_acc: 0.9935 - val_precision: 0.9792 - val_recall: 0.9893\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0279 - acc: 0.9921 - precision: 0.9874 - recall: 0.9802 - val_loss: 0.0210 - val_acc: 0.9941 - val_precision: 0.9909 - val_recall: 0.9837\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0204 - acc: 0.9945 - precision: 0.9938 - recall: 0.9833 - val_loss: 0.0314 - val_acc: 0.9905 - val_precision: 0.9687 - val_recall: 0.9891\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0199 - acc: 0.9943 - precision: 0.9923 - recall: 0.9845 - val_loss: 0.0260 - val_acc: 0.9929 - val_precision: 0.9797 - val_recall: 0.9888\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0225 - acc: 0.9939 - precision: 0.9924 - recall: 0.9830 - val_loss: 0.0263 - val_acc: 0.9912 - val_precision: 0.9919 - val_recall: 0.9739\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0243 - acc: 0.9930 - precision: 0.9908 - recall: 0.9804 - val_loss: 0.0215 - val_acc: 0.9945 - val_precision: 0.9901 - val_recall: 0.9861\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0200 - acc: 0.9940 - precision: 0.9916 - recall: 0.9833 - val_loss: 0.0259 - val_acc: 0.9919 - val_precision: 0.9827 - val_recall: 0.9827\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0194 - acc: 0.9943 - precision: 0.9919 - recall: 0.9859 - val_loss: 0.0215 - val_acc: 0.9943 - val_precision: 0.9898 - val_recall: 0.9859\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0173 - acc: 0.9949 - precision: 0.9931 - recall: 0.9860 - val_loss: 0.0229 - val_acc: 0.9936 - val_precision: 0.9946 - val_recall: 0.9808\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0226 - acc: 0.9937 - precision: 0.9922 - recall: 0.9814 - val_loss: 0.0217 - val_acc: 0.9946 - val_precision: 0.9896 - val_recall: 0.9872\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0171 - acc: 0.9951 - precision: 0.9940 - recall: 0.9867 - val_loss: 0.0227 - val_acc: 0.9944 - val_precision: 0.9995 - val_recall: 0.9792\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0183 - acc: 0.9949 - precision: 0.9944 - recall: 0.9858 - val_loss: 0.0180 - val_acc: 0.9951 - val_precision: 0.9920 - val_recall: 0.9869\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0157 - acc: 0.9954 - precision: 0.9938 - recall: 0.9877 - val_loss: 0.0235 - val_acc: 0.9939 - val_precision: 0.9888 - val_recall: 0.9867\n",
      "Found good model!!\n",
      "################################\n",
      "3 (0,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 26ms/step - loss: 0.5810 - acc: 0.7399 - precision: 0.2536 - recall: 0.1432 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5653 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5654 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5674 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5673 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5652 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5651 - acc: 0.7475 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "################################\n",
      "3 (1,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 24ms/step - loss: 0.5701 - acc: 0.7405 - precision: 0.2379 - recall: 0.1290 - val_loss: 0.4544 - val_acc: 0.7457 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1725 - acc: 0.9616 - precision: 0.9940 - recall: 0.9564 - val_loss: 0.0752 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0598 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0488 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0347 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0197 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0150 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0121 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0100 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0085 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0073 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0064 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0056 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0050 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0045 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0040 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0036 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0030 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0028 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0025 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0024 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0022 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0018 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0016 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0015 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0013 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0011 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0011 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0010 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7724e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.4798e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2497e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 8.9762e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7622e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 8.5078e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3088e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 8.0706e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8861e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 7.6623e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4900e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 7.2806e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1193e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 6.9231e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7725e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 6.5874e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4466e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 6.2725e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1401e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 5.9765e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8526e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 5.6981e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5820e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 5.4358e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3265e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 5.1882e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0854e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 4.9545e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8573e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 4.7335e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6421e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 4.5245e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4381e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 4.3266e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2447e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 4.1392e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0619e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 3.9614e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8881e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.7925e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7230e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.6324e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5669e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 3.4802e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4181e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.3356e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2766e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.1980e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1422e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 3.0670e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0139e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.9420e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8914e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.8232e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7749e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 2.7098e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6641e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 2.6016e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5583e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.4985e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4566e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 2.3998e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3605e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 2.3058e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2677e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.2158e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1797e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.1297e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0952e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.0475e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0143e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.9687e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9373e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.8935e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8634e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.8214e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7927e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.7523e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7249e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.6862e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6598e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.6228e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5976e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.5620e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5378e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.5037e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4805e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.4478e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4256e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.3942e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3729e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.3427e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3224e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found good model!!\n",
      "################################\n",
      "4 (0,)\n",
      "##################################\n",
      "Epoch 1/80\n",
      "69/69 [==============================] - 4s 24ms/step - loss: 0.4208 - acc: 0.8339 - precision: 0.5560 - recall: 0.5672 - val_loss: 0.1226 - val_acc: 0.9943 - val_precision: 0.9937 - val_recall: 0.9856\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0717 - acc: 0.9978 - precision: 0.9968 - recall: 0.9945 - val_loss: 0.0402 - val_acc: 0.9991 - val_precision: 1.0000 - val_recall: 0.9973\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1598 - acc: 0.9602 - precision: 0.9292 - recall: 0.9138 - val_loss: 0.0710 - val_acc: 0.9957 - val_precision: 0.9970 - val_recall: 0.9894\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0446 - acc: 0.9986 - precision: 0.9992 - recall: 0.9957 - val_loss: 0.0258 - val_acc: 0.9993 - val_precision: 1.0000 - val_recall: 0.9976\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0199 - acc: 0.9994 - precision: 0.9995 - recall: 0.9983 - val_loss: 0.0141 - val_acc: 0.9997 - val_precision: 0.9997 - val_recall: 0.9995\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0126 - acc: 0.9997 - precision: 0.9998 - recall: 0.9990 - val_loss: 0.0107 - val_acc: 0.9996 - val_precision: 1.0000 - val_recall: 0.9989\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0108 - acc: 0.9994 - precision: 0.9993 - recall: 0.9983 - val_loss: 0.0086 - val_acc: 0.9998 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0084 - acc: 0.9998 - precision: 0.9998 - recall: 0.9993 - val_loss: 0.0072 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0071 - acc: 0.9998 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.0062 - val_acc: 0.9999 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0060 - acc: 0.9999 - precision: 0.9999 - recall: 0.9997 - val_loss: 0.0054 - val_acc: 0.9999 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0055 - acc: 0.9998 - precision: 0.9998 - recall: 0.9995 - val_loss: 0.0047 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0053 - acc: 0.9997 - precision: 0.9999 - recall: 0.9990 - val_loss: 0.0042 - val_acc: 1.0000 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0044 - acc: 0.9998 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.0047 - val_acc: 0.9995 - val_precision: 1.0000 - val_recall: 0.9984\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0040 - acc: 0.9998 - precision: 0.9999 - recall: 0.9994 - val_loss: 0.0034 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 1.0000 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0031 - val_acc: 0.9999 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0029 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0026 - acc: 1.0000 - precision: 0.9999 - recall: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0024 - acc: 0.9999 - precision: 0.9999 - recall: 0.9998 - val_loss: 0.0027 - val_acc: 0.9998 - val_precision: 0.9992 - val_recall: 1.0000\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0068 - acc: 0.9981 - precision: 0.9976 - recall: 0.9949 - val_loss: 0.0040 - val_acc: 0.9992 - val_precision: 1.0000 - val_recall: 0.9970\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0028 - acc: 0.9997 - precision: 0.9997 - recall: 0.9992 - val_loss: 0.0019 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0019 - acc: 1.0000 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0017 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0015 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_acc: 0.9999 - val_precision: 0.9995 - val_recall: 1.0000\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9999 - precision: 0.9998 - recall: 0.9999 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0011 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0010 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.8053e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4964e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.1862e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8627e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 8.6345e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3237e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 8.1285e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9687e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 7.8991e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4088e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 7.2326e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0170e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 6.8357e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6444e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 6.4646e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2659e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 6.1273e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9669e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 5.8087e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6574e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 5.5192e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4150e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 5.2333e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0896e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 4.9777e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8462e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 4.7348e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6542e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 4.5104e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4112e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 4.2950e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2059e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 4.0972e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0664e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.9049e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8042e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 3.7284e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6405e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.5595e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4752e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.4002e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3541e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.2518e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1978e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.1076e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0342e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.9747e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9081e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.8471e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7890e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.7256e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6671e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.6116e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6129e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.5010e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4597e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.3999e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5534e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.2991e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2634e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.2050e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1771e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.1151e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0727e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 2.0300e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9916e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.9483e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9155e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.8706e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8440e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.7965e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7656e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.7258e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7021e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.6588e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7406e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 1.5942e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5776e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.5320e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5452e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.4730e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4447e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.4165e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4251e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.3624e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3380e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.3109e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2903e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.2609e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2437e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.2134e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2068e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.1678e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1688e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 1.1241e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1114e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 1.0821e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0710e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 1.0420e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0351e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 1.0032e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8685e-05 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.6638e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5404e-05 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Found good model!!\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "for cls in range(5):\n",
    "    found_good = False\n",
    "    for size in range(1,4):\n",
    "        for comb in combinations([0,1,2], size):\n",
    "            print(\"################################\")\n",
    "            print(cls,comb)\n",
    "            print(\"##################################\")\n",
    "            result = train_model(cls, comb)\n",
    "            all_models.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "69/69 [==============================] - 12s 65ms/step - loss: 0.3667 - acc: 0.8732 - precision: 0.6538 - recall: 0.6568 - val_loss: 0.1597 - val_acc: 0.9692 - val_precision: 0.9942 - val_recall: 0.8864\n",
      "Epoch 2/80\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.1115 - acc: 0.9788 - precision: 0.9702 - recall: 0.9458 - val_loss: 0.0680 - val_acc: 0.9887 - val_precision: 0.9854 - val_recall: 0.9702\n",
      "Epoch 3/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0560 - acc: 0.9899 - precision: 0.9893 - recall: 0.9710 - val_loss: 0.0421 - val_acc: 0.9931 - val_precision: 0.9953 - val_recall: 0.9778\n",
      "Epoch 4/80\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 0.0365 - acc: 0.9941 - precision: 0.9941 - recall: 0.9832 - val_loss: 0.0249 - val_acc: 0.9968 - val_precision: 0.9978 - val_recall: 0.9919\n",
      "Epoch 5/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 0.0232 - acc: 0.9972 - precision: 0.9969 - recall: 0.9931 - val_loss: 0.0155 - val_acc: 0.9992 - val_precision: 0.9986 - val_recall: 0.9992\n",
      "Epoch 6/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0147 - acc: 0.9989 - precision: 0.9991 - recall: 0.9969 - val_loss: 0.0113 - val_acc: 0.9997 - val_precision: 0.9989 - val_recall: 1.0000\n",
      "Epoch 7/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0109 - acc: 0.9995 - precision: 0.9993 - recall: 0.9988 - val_loss: 0.0084 - val_acc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 8/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0083 - acc: 0.9997 - precision: 0.9998 - recall: 0.9989 - val_loss: 0.0070 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0158 - acc: 0.9972 - precision: 0.9951 - recall: 0.9933 - val_loss: 0.0068 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0065 - acc: 0.9998 - precision: 0.9994 - recall: 0.9998 - val_loss: 0.0053 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0051 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 0.0045 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0044 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 0.0040 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0039 - acc: 0.9999 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0035 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0034 - acc: 0.9999 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0031 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0031 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 0.0028 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0028 - acc: 0.9999 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0025 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0025 - acc: 0.9999 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0023 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0023 - acc: 0.9999 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0021 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0019 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0017 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0016 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0015 - acc: 1.0000 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0042 - val_acc: 0.9990 - val_precision: 0.9946 - val_recall: 1.0000\n",
      "Epoch 24/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0017 - acc: 0.9999 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0201 - val_acc: 0.9937 - val_precision: 1.0000 - val_recall: 0.9764\n",
      "Epoch 25/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0071 - acc: 0.9986 - precision: 0.9964 - recall: 0.9979 - val_loss: 0.0016 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0014 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/80\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.0012 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.0011 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0010 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4661e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 9.3967e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8374e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/80\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 8.7613e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2597e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/80\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 8.2086e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7572e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 7.7117e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3063e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 7.2540e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8832e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/80\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 6.8387e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4932e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 6.4575e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1361e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 6.1041e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8079e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 5.7780e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5064e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 5.4756e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2166e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/80\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 5.1923e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9560e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 4.9303e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7090e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 4.6847e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4780e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 4.4565e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2615e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 4.2423e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0574e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 4.0404e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8674e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 3.8503e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6893e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 3.6713e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5218e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 3.5037e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3600e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 3.3447e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2122e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 3.1954e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0686e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 3.0537e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9325e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 2.9200e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8076e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 2.7933e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6868e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 2.6728e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5711e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 2.5592e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4615e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 2.4505e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3603e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/80\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 2.3478e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2616e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 2.2502e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1677e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 2.1576e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0803e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/80\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 2.0689e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9951e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.9849e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9149e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 1.9044e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8383e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.8280e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7650e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.7549e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6954e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.6855e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6287e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/80\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 1.6189e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5652e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.5555e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5046e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.4947e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4467e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.4366e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3913e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.3813e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3386e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/80\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 1.3281e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2891e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.2776e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2396e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.2285e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1929e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/80\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 1.1820e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1495e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/80\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 1.1372e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1069e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.0945e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0659e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/80\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.0535e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0297e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.0142e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9378e-05 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 9.7661e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5909e-05 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/80\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 9.4032e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3220e-05 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_models.append(train_model(4,(2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (0,), <keras.engine.sequential.Sequential object at 0x7efbfe674880>, 1.0, 1.0)\n",
      "(1, (0,), <keras.engine.sequential.Sequential object at 0x7efab813cdf0>, 0.0, 0.0)\n",
      "(1, (1,), <keras.engine.sequential.Sequential object at 0x7efab8714580>, 1.0, 0.9973219037055969)\n",
      "(2, (0,), <keras.engine.sequential.Sequential object at 0x7efab02c8d60>, 0.0, 0.0)\n",
      "(2, (1,), <keras.engine.sequential.Sequential object at 0x7efb5c2e5580>, 0.0, 0.0)\n",
      "(2, (2,), <keras.engine.sequential.Sequential object at 0x7efb6c483970>, 0.9820652008056641, 0.9634764194488525)\n",
      "(2, (0, 1), <keras.engine.sequential.Sequential object at 0x7efaf4112910>, 0.0, 0.0)\n",
      "(2, (0, 2), <keras.engine.sequential.Sequential object at 0x7efb0dbbae50>, 0.9989100694656372, 0.9773393869400024)\n",
      "(2, (1, 2), <keras.engine.sequential.Sequential object at 0x7efb0d98afd0>, 0.9887790679931641, 0.986670196056366)\n",
      "(3, (0,), <keras.engine.sequential.Sequential object at 0x7efb0d87e190>, 0.0, 0.0)\n",
      "(3, (1,), <keras.engine.sequential.Sequential object at 0x7efb0f9ddfd0>, 1.0, 1.0)\n",
      "(4, (0,), <keras.engine.sequential.Sequential object at 0x7efaa1768820>, 1.0, 1.0)\n",
      "(4, (0, 2), <keras.engine.sequential.Sequential object at 0x7efb07056370>, 1.0, 1.0)\n",
      "(4, (2,), <keras.engine.sequential.Sequential object at 0x7efaf79ddc10>, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for res in all_models:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (0,), <keras.engine.sequential.Sequential object at 0x7efbfe674880>, 1.0, 1.0)\n",
      "(1, (1,), <keras.engine.sequential.Sequential object at 0x7efab8714580>, 1.0, 0.9973219037055969)\n",
      "(2, (2,), <keras.engine.sequential.Sequential object at 0x7efb6c483970>, 0.9820652008056641, 0.9634764194488525)\n",
      "(3, (1,), <keras.engine.sequential.Sequential object at 0x7efb0f9ddfd0>, 1.0, 1.0)\n",
      "(4, (0,), <keras.engine.sequential.Sequential object at 0x7efaa1768820>, 1.0, 1.0)\n",
      "(4, (0, 2), <keras.engine.sequential.Sequential object at 0x7efb07056370>, 1.0, 1.0)\n",
      "(4, (2,), <keras.engine.sequential.Sequential object at 0x7efaf79ddc10>, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "filtered = []\n",
    "for cls,signals,model,prec,rec in all_models:\n",
    "    if prec <= 0.5 or rec <= 0.5:\n",
    "        continue\n",
    "    if len(signals) > 1:\n",
    "        if any(res[3] <= 0.5 or res[4] <= 0.5 for res in all_models if res[0] == cls and len(res[1])==1 and res[1][0] in signals):\n",
    "            continue\n",
    "    filtered.append((cls,signals,model,prec,rec))\n",
    "for f in filtered:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "for cls,signals,model,prec,rec in filtered:\n",
    "    model_json = model.to_json()\n",
    "    with open(f\"models/model_{cls}_{signals}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f\"models/model_{cls}_{signals}.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "3 [1]\n",
      "Loaded model from disk\n",
      "0 [0]\n",
      "Loaded model from disk\n",
      "1 [1]\n",
      "Loaded model from disk\n",
      "2 [2]\n",
      "Loaded model from disk\n",
      "4 [0, 2]\n",
      "Loaded model from disk\n",
      "4 [0]\n",
      "Loaded model from disk\n",
      "4 [2]\n"
     ]
    }
   ],
   "source": [
    "for path in [p for p in Path(\"models\").iterdir() if p.suffix == \".json\"]:\n",
    "    json_file = open(str(path), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(f\"models/{path.stem}.h5\")\n",
    "    loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc',tf.keras.metrics.Precision(thresholds=0.4),tf.keras.metrics.Recall(thresholds=0.4)])\n",
    "    print(\"Loaded model from disk\")\n",
    "    splitted = path.stem.split(\"_\")\n",
    "    cls = int(splitted[1])\n",
    "    signals = [int(num) for num in splitted[2][1:-1].split(\",\") if num]\n",
    "    print(cls,signals)\n",
    "    good_models.append((cls,signals,loaded_model))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, [1], <keras.engine.sequential.Sequential at 0x7efaf7e8b910>),\n",
       " (0, [0], <keras.engine.sequential.Sequential at 0x7efaa9bd52b0>),\n",
       " (1, [1], <keras.engine.sequential.Sequential at 0x7efab1643700>),\n",
       " (2, [2], <keras.engine.sequential.Sequential at 0x7efaf7e49e20>),\n",
       " (4, [0, 2], <keras.engine.sequential.Sequential at 0x7efab165ef40>),\n",
       " (4, [0], <keras.engine.sequential.Sequential at 0x7efaa9a895e0>),\n",
       " (4, [2], <keras.engine.sequential.Sequential at 0x7efaf7e57310>)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperModel():\n",
    "    def __init__(cls,signals,model,submodels):\n",
    "        self.cls = cls\n",
    "        self.signals = signals\n",
    "        self.submodels = {}\n",
    "        for cs,sg,model in submodels:\n",
    "            self.submodels[sg[0]] = model\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return sel.model.predict(tf.gather(X, self.signals, axis=2))\n",
    "    \n",
    "    def explain_single(self,x):\n",
    "        for signal,model in self.submodels.items():\n",
    "            start, finish = 0,x.shape[1]\n",
    "            while True:\n",
    "                new_start,new_finish = 999,-1\n",
    "                l = finish-start\n",
    "                for i in range(6):\n",
    "                    s,f = start+i*(l//8), start+(i+2)*(l//8)\n",
    "                    print(s,f)\n",
    "                return\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[0,:,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "1\n",
      "0 14\n",
      "tf.Tensor(\n",
      "[[[ 0.48574278]\n",
      "  [ 0.7245592 ]\n",
      "  [ 0.8955255 ]\n",
      "  [ 1.0101544 ]\n",
      "  [ 1.1560017 ]\n",
      "  [ 1.0941502 ]\n",
      "  [ 0.9175775 ]\n",
      "  [ 0.92201954]\n",
      "  [ 0.54237837]\n",
      "  [ 0.30428258]\n",
      "  [ 0.19900708]\n",
      "  [-0.18445724]\n",
      "  [-0.45634368]\n",
      "  [-0.51709527]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.99963295]]\n",
      "7 21\n",
      "tf.Tensor(\n",
      "[[[ 0.92201954]\n",
      "  [ 0.54237837]\n",
      "  [ 0.30428258]\n",
      "  [ 0.19900708]\n",
      "  [-0.18445724]\n",
      "  [-0.45634368]\n",
      "  [-0.51709527]\n",
      "  [-0.68251854]\n",
      "  [-0.958532  ]\n",
      "  [-0.9456677 ]\n",
      "  [-0.90550166]\n",
      "  [-0.69509214]\n",
      "  [-0.5345135 ]\n",
      "  [-0.31065106]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.99963427]]\n",
      "14 28\n",
      "tf.Tensor(\n",
      "[[[-0.68251854]\n",
      "  [-0.958532  ]\n",
      "  [-0.9456677 ]\n",
      "  [-0.90550166]\n",
      "  [-0.69509214]\n",
      "  [-0.5345135 ]\n",
      "  [-0.31065106]\n",
      "  [-0.07081757]\n",
      "  [ 0.06266696]\n",
      "  [ 0.3674488 ]\n",
      "  [ 0.60680825]\n",
      "  [ 0.9214602 ]\n",
      "  [ 1.036375  ]\n",
      "  [ 1.1345189 ]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.999635]]\n",
      "21 35\n",
      "tf.Tensor(\n",
      "[[[-0.07081757]\n",
      "  [ 0.06266696]\n",
      "  [ 0.3674488 ]\n",
      "  [ 0.60680825]\n",
      "  [ 0.9214602 ]\n",
      "  [ 1.036375  ]\n",
      "  [ 1.1345189 ]\n",
      "  [ 1.0832088 ]\n",
      "  [ 0.9509106 ]\n",
      "  [ 0.92655987]\n",
      "  [ 0.7288981 ]\n",
      "  [ 0.43851897]\n",
      "  [ 0.35548586]\n",
      "  [ 0.07828952]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.99963546]]\n",
      "28 42\n",
      "tf.Tensor(\n",
      "[[[ 1.0832088 ]\n",
      "  [ 0.9509106 ]\n",
      "  [ 0.92655987]\n",
      "  [ 0.7288981 ]\n",
      "  [ 0.43851897]\n",
      "  [ 0.35548586]\n",
      "  [ 0.07828952]\n",
      "  [-0.17626065]\n",
      "  [-0.40927234]\n",
      "  [-0.73506635]\n",
      "  [-0.7455455 ]\n",
      "  [-0.9064463 ]\n",
      "  [-0.92474   ]\n",
      "  [-0.82077247]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.9996057]]\n",
      "35 49\n",
      "tf.Tensor(\n",
      "[[[-0.17626065]\n",
      "  [-0.40927234]\n",
      "  [-0.73506635]\n",
      "  [-0.7455455 ]\n",
      "  [-0.9064463 ]\n",
      "  [-0.92474   ]\n",
      "  [-0.82077247]\n",
      "  [-0.5971574 ]\n",
      "  [-0.5031558 ]\n",
      "  [-0.36376786]\n",
      "  [-0.10318134]\n",
      "  [ 0.20011644]\n",
      "  [ 0.60426766]\n",
      "  [ 0.7856456 ]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[0.5254656]]\n",
      "42 56\n",
      "tf.Tensor(\n",
      "[[[-0.5971574 ]\n",
      "  [-0.5031558 ]\n",
      "  [-0.36376786]\n",
      "  [-0.10318134]\n",
      "  [ 0.20011644]\n",
      "  [ 0.60426766]\n",
      "  [ 0.7856456 ]\n",
      "  [ 0.8883414 ]\n",
      "  [ 1.0458682 ]\n",
      "  [ 1.0605118 ]\n",
      "  [ 1.1018208 ]\n",
      "  [ 1.0038891 ]\n",
      "  [ 0.79051596]\n",
      "  [ 0.74380237]]], shape=(1, 14, 1), dtype=float32)\n",
      "[[5.4550248e-05]]\n",
      "49 59\n",
      "tf.Tensor(\n",
      "[[[0.8883414 ]\n",
      "  [1.0458682 ]\n",
      "  [1.0605118 ]\n",
      "  [1.1018208 ]\n",
      "  [1.0038891 ]\n",
      "  [0.79051596]\n",
      "  [0.74380237]\n",
      "  [0.34067154]\n",
      "  [0.10863214]\n",
      "  [0.        ]]], shape=(1, 10, 1), dtype=float32)\n",
      "[[5.3210137e-05]]\n"
     ]
    }
   ],
   "source": [
    "cls,signals, model = good_models[0]\n",
    "signal = signals[0]\n",
    "print(type(cls))\n",
    "print(signal)\n",
    "start, finish = 0,59\n",
    "while True:\n",
    "    new_start,new_finish = 999,-1\n",
    "    l = finish-start\n",
    "    for i in range(8):\n",
    "        s,f = start+i*(l//8), min(start+(i+2)*(l//8), finish)\n",
    "        print(s,f)\n",
    "        print(X[0:1,s:f,signal:signal+1])\n",
    "        print(model.predict(X[0:1,0:f,signal:signal+1]))\n",
    "        if True:#model found sth\n",
    "            new_start = min(new_start, s)\n",
    "            new_finish = max(new_finish, f)\n",
    "    if new_start == start and new_finish == finish:\n",
    "        break\n",
    "    start, finish = new_start, new_finish\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.36391428, 0.54140264, 0.6616599 , 0.70790654, 0.7610961 ,\n",
       "       0.8069586 , 0.876103  , 1.0782043 , 1.0940691 , 1.0836558 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,0:10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 6, 10, 1)          0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 6, 1)             21675     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 1)                0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,675\n",
      "Trainable params: 21,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((-1,10,1), input_shape=(60,1)))\n",
    "model.add(TimeDistributed(good_models[0][2]))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.compile('adam', loss='binary_crossentropy', metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_proj]",
   "language": "python",
   "name": "conda-env-dl_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
