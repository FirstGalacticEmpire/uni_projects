{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informed search - the A* algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth-first search and breadth-first search considered in the previous lesson are completely *blind* algorithms: they're only concerned whether the currently considered state is a goal state or not. They're unable to distinguish whether a state is easy or hard to reach, or whether it is near or far of the goal. This makes them very inefficient search algorithms. To allievate the issue, we introduce informed search algorithms. The information is given to an algorithm in two ways:\n",
    "\n",
    "1. By using an *action cost* function $c(s,a)$, which, given a state $s$ and an action $a$ available in this state, returns its cost as a non-negative number.\n",
    "2. By using a *heuristic* $h(s)$, which, given a state, estimates the lowest cost to reach a goal state from the given state.\n",
    "\n",
    "Given a sequence of actions $a_1, \\ldots, a_n$ and an initial state $s_1$, we can express the *total cost* of reaching the state $s_{n+1}$ by executing the sequence as:\n",
    "$$ c(s_1, a_1, \\ldots, a_{n-1}) = \\sum_{i=1}^n c(s_i, a_i) $$\n",
    "and the *expected cost* of the solution as the sum of the total cost and the estimate cost of reaching the goal from the state $s_{n+1}$\n",
    "$$ f(s_1, a_1, \\ldots, a_n) = c(s_1, a_1, \\ldots, a_n) + h(s_{n+1}) $$\n",
    "\n",
    "The heuristic function is a bit tricky, because we want it to have two properties:\n",
    "* *Admissibility*: It must never *overestimate* the true cost of reaching the goal. \n",
    "* *Consistency*: Let $s$ be a state such that $a$ is an available action in this state and $s'$ is the state reached by executing this action. The heuristic should fulfil triangle inequality, that is, the estimated cost to reach the goal from $s$ should be no greater than the cost of executing the action $a$ + the estimated cost of reaching the goal from the new state.\n",
    "$$ h(s) \\leq c(s, a) + h(s') $$\n",
    "\n",
    "One can prove that admissibility follows from consistency, but consistency is important only if there are multiple paths to reach the same state (i.e., we are searching in a graph, not in a tree). Otherwise, admissability is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets extend the class `Problem` from the previous lesson with two new functions `action_cost` and `heuristic`, which correspond to the functions $c(s,a)$ and $h(s)$ described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "class Problem:\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        ...\n",
    "        \n",
    "    def available_actions(self, state):\n",
    "        ...        \n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        ...\n",
    "        return new_state\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        ...\n",
    "        \n",
    "    def action_cost(self, state, action) -> float:\n",
    "        ...\n",
    "        \n",
    "    def heuristic(self, state) -> float:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a concrete example, lets revisit the vacuum world. \n",
    "\n",
    "![](aima-images/fig2_2.png)\n",
    "\n",
    "Below, we assume a very simple model:\n",
    "* Any action costs 1. This corresponds to searching for the shortest plan.\n",
    "* The heuristic estimation is the number of fields which are still dirty. \n",
    "\n",
    "\n",
    "Lets consider the properties of the heuristic:\n",
    "* Is is admissible? The heuristic value is equal to the number of 'Suck' actions that are yet to be executed and ignores the spatial aspect (i.e., moving between the rooms), thus never overestimating.\n",
    "* Is it consistent? As a consequence of a single action the heuristic value can decrease by at most 1 (if the action happens to be 'Suck' and the room is dirty). The cost of any action is 1, so rewriting the triangle inequality we arrive at:\n",
    "$$ h(s) \\leq c(s, a) + h(s') = \\begin{cases} 1 + (h(s)-1) & a=\\text{'Suck' and the room was dirty} \\\\ 1 + h(s) & \\text{otherwise} \\end{cases} $$\n",
    "* Is it the best we could have? By no means! We could include the spatial aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacuumProblem(Problem):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return (0, (True, True))\n",
    "    \n",
    "    def available_actions(self, state):\n",
    "        return [\"Left\", \"Suck\", \"Right\"]\n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        robot, dirty = state\n",
    "        if action == \"Left\":\n",
    "            return (max(robot-1, 0), dirty)\n",
    "        elif action == \"Suck\":\n",
    "            new_dirty = list(dirty)\n",
    "            new_dirty[robot] = False\n",
    "            return (robot, tuple(new_dirty))\n",
    "        elif action == \"Right\":\n",
    "            return (min(robot+1, len(dirty)-1), dirty)        \n",
    "        raise Exception('Invalid action')\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        return not any(state[1])\n",
    "    \n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return sum(state[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the A* algorithm\n",
    "\n",
    "To implement the A* algorithm you must have a priority queue. Luckily, Python comes with one, so you don't need to implement it by yourself. Then, the algorithm is very simple: \n",
    "1. Start with a queue containing a single item - the initial state\n",
    "2. Repeat until the queue is not empty:\n",
    "  1. Pick an item with the lowest expected cost\n",
    "  2. If this is the goal, return the sequence of actions necessary to reach this state\n",
    "  3. Otherwise, for each available action, create a new entry in the queue corresponding to the state reached after executing the action.\n",
    "  \n",
    "Guard the algorithm against infinite loops: if you already visited a state, you don't need to visit it again (if your heuristic is consistent).\n",
    "\n",
    "In the cell below implement the algorithm in a similar manner as the BFS and DFS in the previous lesson: the sole argument is an object of the class Problem and the function should return a list of actions to achieve a goal state from the initial state.\n",
    "If it is impossible to reach the goal, return `None`.\n",
    "Count the number of states visited during the search and print in out before returning from the function, it will be useful later on to compare different heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(node):\n",
    "    action_list = []\n",
    "    while node.parent is not None:\n",
    "        action_list.append(node.action)\n",
    "        node = node.parent\n",
    "    print(\"Len of solution: \", len(action_list))\n",
    "    return action_list[::-1]\n",
    "\n",
    "\n",
    "class Node2:\n",
    "    def __init__(self, problem, state, parent, action, path_cost, heuristic_cost):\n",
    "        self.problem = problem\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.path_cost = path_cost\n",
    "        self.heuristic_cost = heuristic_cost\n",
    "        self.f_cost = self.path_cost + self.heuristic_cost\n",
    "\n",
    "    # if heapq starts to compare node with node, it means, that nodes are identical\n",
    "    def __lt__(self, other):\n",
    "        return False\n",
    "\n",
    "\n",
    "def astar(problem):\n",
    "    initial_node = Node2(problem=problem, state=problem.initial_state, parent=None, action=None, path_cost=0,\n",
    "                         heuristic_cost=problem.heuristic(problem.initial_state))\n",
    "    explored_states = []\n",
    "    priority_queue = [(initial_node.f_cost, (0, problem.initial_state, initial_node))]\n",
    "    while priority_queue:\n",
    "        priority, data_set = heapq.heappop(priority_queue)\n",
    "        current_path_cost, current_state, node = data_set\n",
    "        if current_state in explored_states:\n",
    "            continue\n",
    "        explored_states.append(current_state)\n",
    "        if problem.is_goal(current_state):\n",
    "            return node\n",
    "        for action in problem.available_actions(state=current_state):\n",
    "            next_state = problem.do_action(current_state, action)\n",
    "            if next_state not in explored_states:\n",
    "                child_node = Node2(problem=problem, state=next_state, parent=node, action=action,\n",
    "                                   path_cost=problem.action_cost(current_state, action) + current_path_cost,\n",
    "                                   heuristic_cost=problem.heuristic(next_state))\n",
    "                new_element = (child_node.f_cost, (child_node.path_cost, next_state, child_node))\n",
    "                heapq.heappush(priority_queue, new_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test your code in the vacuum world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.5 µs ± 141 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Len of solution:  3\n",
      "['Suck', 'Right', 'Suck']\n"
     ]
    }
   ],
   "source": [
    "%timeit final_node = astar(VacuumProblem())\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Variants of the vacuum world\n",
    "\n",
    "Now lets consider a different take on the vacuum world in which the heuristic is not admissible and increases as the number of dirty fields decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.8 µs ± 137 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Len of solution:  3\n",
      "['Suck', 'Right', 'Suck']\n"
     ]
    }
   ],
   "source": [
    "class VacuumProblem1(VacuumProblem):\n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return len(state[1]) - sum(state[1])\n",
    "    \n",
    "%timeit final_node = astar(VacuumProblem1())\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another in which heuristic grossly overestimates the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 µs ± 25.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Len of solution:  3\n",
      "['Suck', 'Right', 'Suck']\n"
     ]
    }
   ],
   "source": [
    "class VacuumProblem2(VacuumProblem):\n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return 10 * sum(state[1])\n",
    "    \n",
    "%timeit final_node = astar(VacuumProblem2())\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the three heuristic functions (`VacuumProblem`, `VacuumProblem1`, `VacuumProblem2`) is the best? Is it the expected answer given the properties of the heuristics? If not, explain why an unorthodox approach works better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although last heuristic appears to be the best, it is not admissible, because it doesn't satisfy properties of the heuristic. (It overestimates distance to the goal). It is the best, because this problem is solved in the fastest way, if the first possible move is \"SUCK\", and VacuumProblem2 promotes the most this move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: 8-puzzle problem\n",
    "\n",
    "Recall the 8-puzzle problem from the previous lesson. Reuse your code and implement an extended version assuming that each action costs 1. Propose 3 (at least) admissible heuristics. This time don't change the initial state, your solution should be capable enough to solve this.\n",
    "\n",
    "![](aima-images/fig3_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n"
     ]
    }
   ],
   "source": [
    "class PuzzleProblem():\n",
    "    def __init__(self, init_state, goal_state):\n",
    "        self.init_state = init_state\n",
    "        self.goal_state = goal_state\n",
    "        self.how_many_to_count = 0\n",
    "\n",
    "    # Agent should work on immutables\n",
    "    def convert_to_tuple(self, state):\n",
    "        this_tuple = tuple(list([tuple(list(state[0])), tuple(list(state[1])), tuple(list(state[2]))]))\n",
    "        return this_tuple\n",
    "\n",
    "    def convert_to_np_array(self, state):\n",
    "        a_list = []\n",
    "        for x in state:\n",
    "            a_list.append(list(x))\n",
    "        array = np.array(a_list)\n",
    "        return array\n",
    "\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self.convert_to_tuple(self.init_state)\n",
    "\n",
    "    def get_position_of_0(self, state):\n",
    "        position = np.where(state == 0)\n",
    "        return position[0][0], position[1][0]\n",
    "\n",
    "    def available_actions(self, state):\n",
    "        state = self.convert_to_np_array(state)\n",
    "\n",
    "        a, b = self.get_position_of_0(state)\n",
    "        available_actions_ = list()\n",
    "        if b != 0:\n",
    "            available_actions_.append('Left')\n",
    "        if b != 2:\n",
    "            available_actions_.append('Right')\n",
    "        if a != 0:\n",
    "            available_actions_.append('Up')\n",
    "        if a != 2:\n",
    "            available_actions_.append('Down')\n",
    "\n",
    "        return available_actions_\n",
    "\n",
    "    def do_action(self, state, action):\n",
    "        state = self.convert_to_np_array(state)\n",
    "\n",
    "        a, b = self.get_position_of_0(state)\n",
    "        new_state = np.copy(state)\n",
    "        if action == 'Left':\n",
    "            if b == 0:\n",
    "                raise Exception('Invalid action.')\n",
    "            new_state[a][b], new_state[a][b - 1] = new_state[a][b - 1], new_state[a][b]\n",
    "        elif action == 'Right':\n",
    "            if b == 2:\n",
    "                raise Exception('Invalid action.')\n",
    "            new_state[a][b], new_state[a][b + 1] = new_state[a][b + 1], new_state[a][b]\n",
    "        elif action == 'Up':\n",
    "            if a == 0:\n",
    "                raise Exception('Invalid action.')\n",
    "            new_state[a][b], new_state[a - 1][b] = new_state[a - 1][b], new_state[a][b]\n",
    "        elif action == 'Down':\n",
    "            if a == 2:\n",
    "                raise Exception('Invalid action.')\n",
    "            new_state[a][b], new_state[a + 1][b] = new_state[a + 1][b], new_state[a][b]\n",
    "        else:\n",
    "            raise Exception('Invalid action.')\n",
    "\n",
    "        new_state = self.convert_to_tuple(new_state)\n",
    "        return new_state\n",
    "\n",
    "    def is_goal(self, state) -> bool:\n",
    "        state = self.convert_to_np_array(state)\n",
    "        return (state == self.goal_state).all()\n",
    "\n",
    "    def action_cost(self, state, action) -> float:\n",
    "        return 1\n",
    "\n",
    "    class Number:\n",
    "        def __init__(self, state, value):\n",
    "            position = np.where(state == value)\n",
    "            self.y = position[0][0]\n",
    "            self.x = position[1][0]\n",
    "            self.value = value\n",
    "            \n",
    "    def euklidean_distances_of_elements(self, state) -> float:\n",
    "        state = self.convert_to_np_array(state)\n",
    "        current_elements = [PuzzleProblem.Number(state=state, value=x) for x in range(self.how_many_to_count, 9)]\n",
    "        goal_elements = [PuzzleProblem.Number(state=self.goal_state, value=x) for x in\n",
    "                         range(self.how_many_to_count, 9)]\n",
    "        distances = [sqrt((current_element.x - goal_element.x) ** 2) + sqrt((current_element.y - goal_element.y) ** 2)\n",
    "                     for\n",
    "                     current_element, goal_element in zip(current_elements, goal_elements)]\n",
    "        return sum(distances)\n",
    "\n",
    "    def manhatan_distances_of_elements(self, state) -> float:\n",
    "        state = self.convert_to_np_array(state)\n",
    "        current_elements = [PuzzleProblem.Number(state=state, value=x) for x in range(self.how_many_to_count, 9)]\n",
    "        goal_elements = [PuzzleProblem.Number(state=self.goal_state, value=x) for x in\n",
    "                         range(self.how_many_to_count, 9)]\n",
    "        distances = [abs(current_element.x - goal_element.x) + abs(current_element.y - goal_element.y) for\n",
    "                     current_element, goal_element in zip(current_elements, goal_elements)]\n",
    "        return sum(distances)\n",
    "    \n",
    "\n",
    "    def minkowski_distance(self, state) -> float:\n",
    "        p = 1.5\n",
    "        state = self.convert_to_np_array(state)\n",
    "        current_elements = [PuzzleProblem.Number(state=state, value=x) for x in range(self.how_many_to_count, 9)]\n",
    "        goal_elements = [PuzzleProblem.Number(state=self.goal_state, value=x) for x in\n",
    "                         range(self.how_many_to_count, 9)]\n",
    "        distances = [\n",
    "            ((abs(current_element.x - goal_element.x)) ** p + (abs(current_element.y - goal_element.y)) ** p) ** (1 / p)\n",
    "            for\n",
    "            current_element, goal_element in zip(current_elements, goal_elements)]\n",
    "        return sum(distances)\n",
    "\n",
    "    def heuristic(self, state) -> float:\n",
    "        return self.euklidean_distances_of_elements(state)\n",
    "problem = PuzzleProblem(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "final_node = astar(problem)\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08 s ± 6.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "%timeit final_node = astar(problem)\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosen heurystic - euklidean distance of every element from current state to goal state. \n",
    "Euklidean distance will be never longer than real real distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem1(PuzzleProblem):\n",
    "    def heuristic(self, state) -> float:\n",
    "        return self.manhatan_distances_of_elements(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07 s ± 3.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem1(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "%timeit final_node = astar(problem)\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosen heurystic - manhatan distance of every element from current state to goal state. \n",
    "Any action can reduce the distance of any element to goal by at most one, thus heurystic is going to be always smaller than real distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem2(PuzzleProblem):\n",
    "    def heuristic(self, state) -> float:\n",
    "        return self.minkowski_distance(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.67 s ± 9.75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem2(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "%timeit final_node = astar(problem)\n",
    "print(solution(final_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosen heurystic - minkowski distance of every element from current state to goal state. Minkowski distance with p=1.5 is always smaller than manhatan distance, and thus always smaller than the real distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your heuristics on the given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n",
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n",
      "Len of solution:  26\n",
      "['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Down', 'Left', 'Up']\n",
      "\n",
      "Len of solution:  26\n",
      "Len of solution:  26\n",
      "Is plan0==plan1? True\n",
      "Len of solution:  26\n",
      "Len of solution:  26\n",
      "Is plan0==plan2? True\n",
      "Len of solution:  26\n",
      "Len of solution:  26\n",
      "Is plan1==plan2? True\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "final_node = astar(problem)\n",
    "print(solution(final_node))\n",
    "problem1 = PuzzleProblem1(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "final_node1 = astar(problem1)\n",
    "print(solution(final_node1))\n",
    "problem2 = PuzzleProblem2(np.array([[7, 2, 4], [5, 0, 6], [8, 3, 1]]), np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
    "final_node2 = astar(problem2)\n",
    "print(solution(final_node2))\n",
    "print()\n",
    "print(\"Is plan0==plan1?\", solution(final_node) == solution(final_node1))\n",
    "print(\"Is plan0==plan2?\", solution(final_node) == solution(final_node2))\n",
    "print(\"Is plan1==plan2?\", solution(final_node1) == solution(final_node2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the heuristics is the best for this task? Why is that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhatan distance appears to be the best heuristic, it returns an estimation of the distance to the goal with the least amount of calculation. It projects the real distance in the most credible way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "The pictures and the description of 8-puzzle are from \"Artificial Intelligence: A Modern Approach\" 3rd ed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
